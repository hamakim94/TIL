## 0. 컴퓨터는 어떤 논리로 비트를 다루는가

과거 비트를 사용하지 않은 초기 계산 장치 -> 왜 비트가 어울리는지



**하드웨어** : 비트에 대해 동작하는 장치를 포함 모든 물리적인 장치
하드웨어에서 구현하는 것 : **조합 논리**



### 디지털 컴퓨터의 사례

예전에는 맞물리는 두 톱니바퀴 사용
톱니바퀴 사용 X : **계산자** - log(xy) = log(x) + log(y) 사용 곱셈
등등 여러개가 있다.



### 아날로그와 디지털의 차이

계산자 : 1.1 표현 가능, 손가락 : 불가능 => **연속(continuous) vs 이산(discrete)**
**아날로그 : 연속적**, 다만 정밀도의 문제가 있으
**디지털 : 이산적**



### 하드웨어에서 크기가 중요한 이유

아이들  10km 떨어진 학교 등하교, 차의 평균 시속 40km/h라고 하면
한 시간에 최대 2번 왕복이 가능.

**현대 컴퓨터는 아이들 대신 전자를 움직임**
컴퓨터에서 전자의 여행 시간을 최소화 -> 최대한 가깝게!

ex) 컴퓨터 클록 속도 4GHz
1초에 40억가지 계산 처리 가능
40억분의 1초동안 전자가 이동할 수 있는 거리는 최대 75m

예전 CPU : 한 면이 18mm, 두 번 왕복

여행을 하려면 커피와 사람 뿐만 아니라 에너지도 필요
하드웨어를 작게 만들면, 여행 거리 줄어들고, 에너지 양도 줄어들어
전력 소모 감소, 열 발생 감소



### 디지털을 사용하면 더 안정적인 장치를 만들 수 있다.

물체가 너무 작아 -> 서로 간섭하기 아주 쉬움
ex) 계량컵, 물 담기, 이것도 흔들리는데 
수십억 배 작은 컵을 드는데 안 흔들릴까?

이산적인 장치의 장점 : **판정 기준**이 있음
손가락 -> 중간값이 없음.
계산자를 개량해서 정수 위치에서만 멈추도록 **걸쇠** 추가 가능

요즘 칩 안의 선 : 몇 나노미터 : 10^-9m, 
**누화(crosstalk)** 효과 : 신호 간섭, -> **잡음 내성(noise immunity)**을 갖는 디지털 회로 사용 필수



### 아날로그 세계에서 디지털 만들기

**전이 함수(transfer function)** 

예시) x축 : 광선(입력), y축 : 기록된 밝기
빛이 많아 -> 밝기 값이 모여 -> **상단부** -> 최댓값에 가까워져 이미지 노출 과해짐
빛이 적어 -> **하단부** -> 부족
목표 : 노출을 조절해서 **직선부**에 많이 닿게(곡선처럼 생긴거)

예시) 볼륨(증폭 회로)
증폭 함수의 **가파른 정도(게인)**에 따라 볼륨 조절
gain이 11로 고정? -> 엄청 가팔라, 왜곡(distortion) 발생
입력이 전이 함수의 선형 영역에 넘어서기 떄문
가파른 부분 떄문에 출력이 확 달라짐 -> 디지털 형식(이산)같아 -> 판정 기준을 **문턱값(threshold)**

연속적인 공간을 이산적인 영역으로 나눠주네!!
시소 : 맨위나, 맨 아래에 있는게 편하지, 중간 영역 유지는 어려워



### 10진 숫자 대신 비트를 사용하는 이유

컴퓨터에는 손가락이 없어서
전이 함수를 각기 다른 10가지 문턱값으로 구분할 수 있는 간단한 방법이 없어서..