## DNN(심층신경망)



**퍼셉트론(Perceptron)** : 사람의 노 구조를 본따 처음 만들어진 인공 뉴런
다수의 입력이 합산되어 하나의 통로로 출력, 일정 값이상이면 다음 뉴런으로.

**활성함수(Activation Function) :** 다음 뉴런으로 신호를 전달할지..!
퍼셉트로는 0과 1만 가짐, 비선형 문제는 어떻게 해결?
여러 개의 퍼셉트론을 연결

**심층신경망**
은닉층이 2개 이상인 다층 퍼셉트론
전체 식 미분 어려워 OR 미분 불가

**오차 역전파 -> 경사 하강법**
가중치를 수정할 때, 편미분 값을 오차에 곱해 상단 노드에 전달
출력 하고, 오차를 보고, 역으로 수정해나감

다양한 활성함수가 있는데
Adam 씀(Gradient 조정, learning_rate 조정)
SGD 씀



## CNN(합성곱 신경망) - 공간적인 위치

**아이디어**

이미지의 특징을 가장 잘 나타내는 부분으로 학습하자!
필터를 씌워서 학습!

과정

1. Filtering
2. Classfication



**합성곱 계층 : 이미지의 특징 감지**
**풀링 계층 : 정보를 간소화, 계산양 줄임, ( 위 2개 반복)**
**활성화 계층 : 비선형성 도입(ReLU, sigmoid, tanh 사용)**
**완전 연결 계층 : 최종적인 예측 수행**



## RNN & LSTM - 시간적인 순서

### RNN(Recurrent Neural Network)

문장 구조 학습에 용이
동일한 구조의 네트워크가 병렬적으로 연결
길이가 길어지면 문제

### LSTM(Long ShortTerm Memory)

장기 기억(곱하고 더하기) + 단기 기억을 따로 둬서 RNN 문제 해결

GRU(Gated Recurrent Unit)도 있다



## AutoEncoder

데이터를 압축(encode) -> 원래로 복원(decode)
GAN이 있음



