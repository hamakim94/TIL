## 자연어 처리란?

인간의 언어 현상을 컴퓨터와 같은 기계를 이용해 모사할 수 있도록 연구, 이를 구현
인간의 언어로 명령을 내림 -> **기계가 자연어 처리를 통해 이해** -> 결과 전달

cf) 기존 : 인간이 컴퓨터 언어로 명령을 내림



## 자연어 처리 텍스트 분석 절차



### 1. 데이터 수집 단계

Data Collection(수집) / Data Cleansing(정제)

### 2. 텍스트 전처리 단계 => 60% 이상 정제

**Tokenizing(토큰화)**
-- 문장 토큰화(, ? ! 기준), 단어 토큰화(띄어쓰기 기준), 형태소 분석 등

**POS Tagging(품사 부착)**
-- 문법에 따라 분류

**원형 복원(Stemming 어간 추출, Lemmatizing 표제어 추출)**
-- 어간 : 활용시 변하지 않는 부분 ex) 먹다, 먹어 -> 먹
-- 표제어 : 사전에 등록된 단어

**불용어 처리(Stopword)**
-- 의미가 없는 단어 토큰 제거

### 3. 텍스트 분석 단계

주제어 찾기(Topic modeling)
문서 요약(Summarzize)
문서 분류(Category classificition)
감정 분석(Sentiment analysis)

### 4. 시각화

Word Cloud, Pie Chart 등이 있음





## 단어의 표현

### 원 핫 인코딩

문자를 숫자로 표현
ex) 원숭이 = [1, 0, 0]
차원의 크기 한계, 단어의 의미를 담지 못하는 문제점

### 단어 임베딩

단어의 의미를 간직하는 밀집 벡터로 표현!
분포 가설 : 같은 문맥에서 등장하는 단어 유사한 의미

#### cf) 유사도 계산

유클리디언 거리, 코사인 유사도, 자카드 유사도, 레벤슈타인 유사도 등

### n-Gram

복수개(n개) 단어를 보느냐에 따라 unigram, bigram trigram 등으로 구분
특정 도메인별 corpus 학습 -> 더 좋은 성능



# 문서의 표현

문서를 숫자로!

### BoW(Bag of Words)

문자의 빈도수만으로 문서를 표현
단어 순서 고려 X
차원이 낭비되고(1차원 벡터 저장)
많이 나온다고 중요하진 않아!

### TDM, DTM

![스크린샷 2023-11-11 오후 2.43.57](https://p.ipic.vip/7kpc9k.png)

BoW와 문제점이 거의 같음

### TF-IDF

단어 빈도 -> 역문서 빈도
TDM 내 각 단어의 중요성을 가중치로 표현
![스크린샷 2023-11-11 오후 2.45.49](https://p.ipic.vip/joqbd2.png)

특정 문서에서만 많이 표현되는 단어 -> **중요도가 높다**

토큰 Index -> tf 계산 -> IDF 계산 -> 곱



## 키워드 추출(Keyword Extraction)

단어의 중요성을 어떻게?

방법 1. TF-IDF

방법 2.  TextRank(구글 페이지랭크) -> 그래프 -> 재귀적으로 정보 고려



## 문서 요약

1. Luhn Summarize
2. TextRank(문장 단위)



## 문서 분류

나이브 베이즈
SVM
딥러닝 등 있다



## 감정 분석

문서의 긍정 / 부정 파악



### 사전기반 감성분석

정의된 긍정 / 부 사전 활용 -> 일치 단어 등장 여부
사전의 질이 중요

### 나이브베이즈 분류기 활용 감정 분석

감라벨이 부착 학습용 데이터 필요



## 토픽 모델링

문서의 주제찾기

LSA, pLSA, LDA 잠재 디리클레 할당 등등..