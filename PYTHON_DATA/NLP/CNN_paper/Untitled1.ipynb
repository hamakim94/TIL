{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2915/2916 [============================>.] - ETA: 0s - loss: 0.4559 - accuracy: 0.8006INFO:tensorflow:Assets written to: ckpt2\\ckpt-loss=0.46\\assets\n",
      "2916/2916 [==============================] - 97s 33ms/step - loss: 0.4559 - accuracy: 0.8006 - val_loss: 0.4231 - val_accuracy: 0.8064\n",
      "Epoch 2/10\n",
      "2916/2916 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.8124INFO:tensorflow:Assets written to: ckpt2\\ckpt-loss=0.42\\assets\n",
      "2916/2916 [==============================] - 94s 32ms/step - loss: 0.4215 - accuracy: 0.8124 - val_loss: 0.4174 - val_accuracy: 0.8136\n",
      "Epoch 3/10\n",
      "2916/2916 [==============================] - ETA: 0s - loss: 0.4104 - accuracy: 0.8178INFO:tensorflow:Assets written to: ckpt2\\ckpt-loss=0.41\\assets\n",
      "2916/2916 [==============================] - 96s 33ms/step - loss: 0.4104 - accuracy: 0.8178 - val_loss: 0.4097 - val_accuracy: 0.8130\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-124fb1a15622>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\TIL\\NLP\\CNN_paper\\model2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm2_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Model2 실행 및 그래프 작성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "import model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import model3_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 현재 폴더위치에 있습니까?[y/n]y\n",
      "C:\\Users\\User\\TIL\\NLP\\CNN_paper\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 100)      2000000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 30, 100)      2000000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 30, 100)      2000000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 28, 100)      30100       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 27, 100)      40100       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 26, 100)      50100       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 100)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 100)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 100)          0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 100)          0           global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 100)          0           global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 100)          0           global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 300)          0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          30100       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            101         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,150,501\n",
      "Trainable params: 6,150,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "2916/2916 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.8017WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ckpt3\\ckpt-loss=0.44\\assets\n",
      "2916/2916 [==============================] - 278s 95ms/step - loss: 0.4399 - accuracy: 0.8017 - val_loss: 0.3955 - val_accuracy: 0.8228\n",
      "Epoch 2/10\n",
      "2916/2916 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.8500INFO:tensorflow:Assets written to: ckpt3\\ckpt-loss=0.36\\assets\n",
      "2916/2916 [==============================] - 276s 95ms/step - loss: 0.3559 - accuracy: 0.8500 - val_loss: 0.3892 - val_accuracy: 0.8293\n",
      "Epoch 3/10\n",
      "2916/2916 [==============================] - 260s 89ms/step - loss: 0.3114 - accuracy: 0.8721 - val_loss: 0.3989 - val_accuracy: 0.8295\n",
      "Epoch 4/10\n",
      "2916/2916 [==============================] - 288s 99ms/step - loss: 0.2679 - accuracy: 0.8939 - val_loss: 0.4262 - val_accuracy: 0.8234\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7d116eeddba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmodel3_functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\TIL\\NLP\\CNN_paper\\model3_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel3_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;31m# plot 출력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'create'"
     ]
    }
   ],
   "source": [
    "import model3_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model(model):\n",
    "    if model=='model1':checkpoint_dir = './ckpt1'\n",
    "    elif model=='model2': checkpoint_dir = './ckpt2'\n",
    "    else : checkpoint_dir = './ckpt3'\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + '/' + name\n",
    "                   for name in os.listdir(checkpoint_dir)]\n",
    "\n",
    "    latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "    print('Restoring from', latest_checkpoint)\n",
    "    return keras.models.load_model(latest_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from ./ckpt1/ckpt-loss=0.455\n"
     ]
    }
   ],
   "source": [
    "model1 = restore_model('model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from ./ckpt2/ckpt-loss=0.41\n"
     ]
    }
   ],
   "source": [
    "model2 = restore_model('model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from ./ckpt3/ckpt-loss=0.36\n"
     ]
    }
   ],
   "source": [
    "model3 = restore_model('model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x21eec046198>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "k = pd.read_pickle('tokenizer.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x21ed1c83710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  [더빙, 진짜, 짜증나다, 목소리]\n",
       "1                 [흠, 포스터, 보고, 초딩, 영화, 줄, 오버, 연기, 가볍다]\n",
       "2                                 [무재, 밓었, 다그, 래서, 추천]\n",
       "3                 [교도소, 이야기, 구먼, 솔직하다, 재미, 없다, 평점, 조정]\n",
       "4         [몬페, 의, 익살스럽다, 연기, 영화, 스파이더맨, 커스틴, 던스트, 이쁘다]\n",
       "                              ...                     \n",
       "145786                                 [인간, 문제, 소, 죄인]\n",
       "145787                                        [평점, 낮다]\n",
       "145788                  [이, 뭐, 한국인, 먹거리, 필리핀, 혼혈, 착하다]\n",
       "145789                 [청춘, 영화, 최고봉, 방황, 우울하다, 날, 자화상]\n",
       "145790                        [한국, 영화, 최초, 수간, 내용, 영화]\n",
       "Name: tokens, Length: 145791, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = fc.load_data('.')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
