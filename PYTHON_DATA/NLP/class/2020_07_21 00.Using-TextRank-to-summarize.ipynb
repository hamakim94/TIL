{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9-2 Textrank\n",
    "\n",
    "문장간 유사성이 있는 경우는 connection이 있다고 생각한다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![대체 텍스트](https://www.researchgate.net/profile/Khushboo_Thakkar3/publication/232645575/figure/fig1/AS:575720050573312@1514273764062/Sample-graph-build-for-sentence-extraction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 TextRank 직접 구현하기 (Matrix 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"딸기 바나나 사과 파인애플. 바나나 사과 딸기 포도. 복숭아 수박. 파인애플 사과 딸기 바나나.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab(dicpath = 'C:\\mecab\\mecab-ko-dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = Text.split('. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[-1] = sentences[-1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['딸기 바나나 사과 파인애플', '바나나 사과 딸기 포도', '복숭아 수박', '파인애플 사과 딸기 바나나']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('딸기 바나나 사과 파인애플', '복숭아 수박')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_similarity(sentences[0], sentences[2])\n",
    "(sentences[0], sentences[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 문장간 유사도 측정 (자카드 유사도 사용)\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    set1 = set(mecab.pos(sentence1))\n",
    "    set2 = set(mecab.pos(sentence2))\n",
    "    \n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "    \n",
    "\n",
    "sentence_similarity('나는 치킨을 좋아해','나는 치킨을 싫어해')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['딸기 바나나 사과 파인애플 수박', '바나나 사과 딸기 포도', '복숭아 수박', '파인애플 사과 딸기 바나나']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text = \"딸기 바나나 사과 파인애플 수박. 바나나 사과 딸기 포도. 복숭아 수박. 파인애플 사과 딸기 바나나.\"\n",
    "newdoc = sent_tokenize(Text)\n",
    "newdoc\n",
    "for i in range(len(newdoc)):\n",
    "    newdoc[i] = newdoc[i][:-1]\n",
    "newdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_similarity(newdoc[0], newdoc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildMatrix(sentences):\n",
    "    \n",
    "    len_sent = len(sentences)\n",
    "\n",
    "    f_weighted_edge = np.zeros((len_sent, len_sent), np.float32)\n",
    "    weighted_edge = np.zeros((len_sent, len_sent), np.float32)\n",
    "    # we must get first score in order to make score\n",
    "    for i in range(len_sent):\n",
    "        for j in range(len_sent):\n",
    "            if not i == j:\n",
    "                f_weighted_edge[i][j] = sentence_similarity(sentences[i], sentences[j])\n",
    "\n",
    "    score = f_weighted_edge.sum(axis=1)     \n",
    "    # print(score)\n",
    "    # print(weighted_edge)\n",
    "\n",
    "    for i in range(len_sent):\n",
    "        for j in range(len_sent):\n",
    "            \n",
    "            if not i == j:\n",
    "                if score[i] == 0:\n",
    "                    weighted_edge[i][j] = 0\n",
    "                else:\n",
    "                    weighted_edge[i][j] = sentence_similarity(sentences[i], sentences[j])/score[i]\n",
    "\n",
    "    return score, weighted_edge, f_weighted_edge\n",
    "\n",
    "Text = \"딸기 바나나 사과 파인애플 수박. 바나나 사과 딸기 포도. 복숭아 수박. 파인애플 사과 딸기 바나나.\"\n",
    "score , weighted_edge, f_weighted_edge = buildMatrix(newdoc)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.5       , 0.16666667, 0.8       ],\n",
       "        [0.5       , 0.        , 0.        , 0.6       ],\n",
       "        [0.16666667, 0.        , 0.        , 0.        ],\n",
       "        [0.8       , 0.6       , 0.        , 0.        ]], dtype=float32),\n",
       " array([1.4666667 , 1.1       , 0.16666667, 1.4000001 ], dtype=float32))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_weighted_edge, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.3409091 , 0.11363636, 0.54545456],\n",
       "       [0.45454544, 0.        , 0.        , 0.54545456],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.57142854, 0.4285714 , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.6904762, 1.3809524, 0.5714286, 1.6428572], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3966666, 1.085    , 0.2916667, 1.34     ], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.15 + 0.85*np.dot(weighted_edge.T, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 문장 중요도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score, weighted_edge, eps=0.0001, d=0.85, max_iter = 50):\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        prev_score = np.copy(score)\n",
    "        score =  (1 - d)  +  d*np.dot(weighted_edge.T, score)\n",
    "       \n",
    "        if np.sum(np.fabs(score - prev_score)) <= eps:\n",
    "            break\n",
    "                \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4105095, 1.2790778, 1.0246983, 0.2862456], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gotit = scoring(score, weighted_edge)\n",
    "np.sort(gotit)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(gotit)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `sort` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 문서 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def summarize(text, n=10):\n",
    "    newdoc = sent_tokenize(text)\n",
    "    \n",
    "    # 만약 sent_tokenize의 마지막 결과가 .이 포함되면 삭제해줘\n",
    "    if newdoc[0][-1] == '.':\n",
    "        for i in range(len(newdoc)):\n",
    "            newdoc[i] = newdoc[i][:-1]\n",
    "            \n",
    "    score, weighted_edge, f_weighted_edge = buildMatrix(newdoc)\n",
    "    final_score = scoring(score, weighted_edge) # 그럼 이제 최종 스코어랑 문장이랑 짝지어줘서 인덱스를 뽑아와야 함.\n",
    "    \n",
    "    largest = np.argsort(final_score)[::-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    sent = []\n",
    "    for i in range(len(newdoc))[:n]:\n",
    "        sent.append('score : {}, sentences : {}'.format(final_score[largest[i]], newdoc[largest[i]]))\n",
    "    \n",
    "    return sent\n",
    "#     for i in range(len(newdoc))[:n]:\n",
    "#         print('score : {}, sentences : {}'.format(final_score[largest[i]], newdoc[largest[i]]))\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize(Text, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score : 1.410509467124939, sentences : 딸기 바나나 사과 파인애플 수박',\n",
       " 'score : 1.2790777683258057, sentences : 파인애플 사과 딸기 바나나',\n",
       " 'score : 1.024698257446289, sentences : 바나나 사과 딸기 포도']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " top n important sentences :\n",
      "score : 1.410509467124939, sentences : 딸기 바나나 사과 파인애플 수박\n",
      "score : 1.2790777683258057, sentences : 파인애플 사과 딸기 바나나\n",
      "score : 1.024698257446289, sentences : 바나나 사과 딸기 포도\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(Text, 3)\n",
    "print(' top n important sentences :')\n",
    "for sent in summary :\n",
    "    \n",
    "      print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선생님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 TextRank 직접 구현하기 (Matrix 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"딸기 바나나 사과 파인애플. 바나나 사과 딸기 포도. 복숭아 수박. 파인애플 사과 딸기 바나나.\"\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab(dicpath = 'C:\\mecab\\mecab-ko-dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 문장간 유사도 측정 (자카드 유사도 사용)\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    mecab = Mecab(dicpath = 'C:\\mecab\\mecab-ko-dic')\n",
    "    \n",
    "    sentence1 =[ word for word in mecab.pos(sentence1) if word[1][0] in ['N', 'V']]\n",
    "    sentence2 =[ word for word in mecab.pos(sentence2) if word[1][0] in ['N', 'V']]\n",
    "    \n",
    "    union = set(sentence1).union(set(sentence2))\n",
    "    intersection =set(sentence1).intersection(set(sentence2))\n",
    "    \n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "sentence_similarity('나는 치킨을 좋아해','나는 치킨을 싫어해') # 2 / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.46666667, 1.1       , 0.16666667, 1.4       ]),\n",
       " array([[0.        , 0.34090909, 0.11363636, 0.54545455],\n",
       "        [0.45454545, 0.        , 0.        , 0.54545455],\n",
       "        [1.        , 0.        , 0.        , 0.        ],\n",
       "        [0.57142857, 0.42857143, 0.        , 0.        ]]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def buildMatrix(sentences):\n",
    "        \n",
    "        score = np.ones(len(sentences)) # 곱할거니까 받아놔야해..\n",
    "\n",
    "        weighted_edge = np.zeros((len(sentences), len(sentences)))\n",
    "        \n",
    "        for i in range(len(sentences)):\n",
    "            for j in range(len(sentences)):\n",
    "                if i == j:\n",
    "                    continue # 그냥 넘어가~\n",
    "                weighted_edge[i][j] = sentence_similarity(sentences[i], sentences[j])\n",
    "                \n",
    "        for i in range(len(weighted_edge)):\n",
    "            score[i] = weighted_edge[i].sum()\n",
    "            weighted_edge[i] /= score[i]\n",
    "                \n",
    "                \n",
    "        return score, weighted_edge\n",
    "\n",
    "Text = \"딸기 바나나 사과 파인애플 수박. 바나나 사과 딸기 포도. 복숭아 수박. 파인애플 사과 딸기 바나나.\"\n",
    "buildMatrix(sent_tokenize(Text))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 문장 중요도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_init' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-369128a2382d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnewP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mscoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'score_init' is not defined"
     ]
    }
   ],
   "source": [
    "def scoring(A, P, eps=0.0001, d=0.85, max_iter = 50):\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "        \n",
    "        newP = (1-d) + d* (A.T.dot(P))\n",
    "\n",
    "       \n",
    "        if abs((newP - P).sum()) <= eps:\n",
    "            break\n",
    "                \n",
    "    return newP\n",
    "\n",
    "scoring(weighted_edge, score_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 문서 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def summarize(text, n=10):\n",
    "    text = sent_tokenize(text)\n",
    "    score_init, weighted_edge = buildMatrix(text)\n",
    "    print(score_init, weighted_edge)\n",
    "    score = scoring(weighted_edge, score_init)\n",
    "    print(score)\n",
    "    sorted_score = sorted(enumerate(score), key = lambda item: item[i], reverse = True)[:n]\n",
    "    return [(text[s[0]], s[1]) for s in sorted_score]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46666667 1.1        0.16666667 1.4       ] [[0.         0.34090909 0.11363636 0.54545455]\n",
      " [0.45454545 0.         0.         0.54545455]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.57142857 0.42857143 0.         0.        ]]\n",
      "[1.39666667 1.085      0.29166667 1.34      ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-54fbbb632009>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m       \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-115-82f92bcd4bbb>\u001b[0m in \u001b[0;36msummarize\u001b[1;34m(text, n)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0msorted_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted_score\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-115-82f92bcd4bbb>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(item)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0msorted_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted_score\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "summary = summarize(Text, 3)\n",
    "for sent in summary :\n",
    "    \n",
    "      print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이거 변수 넣어서 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 TextRank 직접 구현하기 (Graph 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"딸기 바나나 사과 딸기 파인애플. 바나나 사과 딸기. 복숭아 파인애플. 파인애플 사과 딸기 바나나.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences(text):\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 자카드 유사도\n",
    "\n",
    "- 겹치는 토큰의 비율!!  \n",
    "\n",
    "근데 그러면 score 필요하잖아.. 그러면 어떻게?\n",
    "\n",
    "- 문장 1 -> 문장 2   \n",
    "\n",
    "\n",
    "( 문장 1 - 문장2 유사도) / (문장1 전체 유사도 합(0.5 / (0.5 + 0.8 + 0.167) -> 이거 자체가 score!\n",
    "\n",
    "유사도를 기반으로, 그냥 초기 스코어를 edge 유사도의 합으로 구해(들어온거)  \n",
    "\n",
    "그 다음 egge 가중치\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "# # 문장간 유사도 측정 (자카드 유사도 사용)\n",
    "# def sentence_similarity(sentence1, sentence2):\n",
    "#   pass\n",
    "\n",
    "# sentence_similarity('나는 치킨을 좋아해','나는 치킨을 싫어해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(nodes): # 인덱스별로 받아온다기 보다 문장 자체를 받아서 하나씩 함\n",
    "    return [(start,end, sentence_similarity(start,end)) for start in nodes for end in nodes if start is not end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def rank(nodes,edges):\n",
    "    graph = nx.diamond_graph()\n",
    "    graph.clear()\n",
    "    graph.add_nodes_from(nodes)\n",
    "    graph.add_weighted_edges_from(edges) # 그럼 노드와 엣지가 뭘까> 확인을 해보자\n",
    "    \n",
    "    return nx.pagerank(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 문서 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text,num_summaries=3):\n",
    "    nodes = sentences(text)\n",
    "    print(nodes) # 문장이 나왔고\n",
    "    edges = connect(nodes)\n",
    "    scores = rank(nodes, edges)\n",
    "    print(scores) # 문장에 대한 score가 \n",
    "    return sorted(scores.items(), key=lambda x: x[1], reverse=True)[:num_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### cf) lambda\n",
    "현재 구조 score.item()\n",
    "{ s1 : 0.2, s2 : 0.5, s3 = 0.1} \n",
    "보통 딕셔너리는 key가 기준이니, value로 만들어야하니\n",
    "lambda x 를 가져오면 # 함수로 , 그냥 간편하게 내용만 갖고 있는 함수이다., 아 그래서 x에 들어가는 값은 scores.items() 가 들어감\n",
    "# 그래서 x[1] 이면 value겠지!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['딸기 바나나 사과 딸기 파인애플.', '바나나 사과 딸기.', '복숭아 파인애플.', '파인애플 사과 딸기 바나나.']\n",
      "{'딸기 바나나 사과 딸기 파인애플.': 0.3270626958069155, '바나나 사과 딸기.': 0.25134837504171265, '복숭아 파인애플.': 0.09452623334445671, '파인애플 사과 딸기 바나나.': 0.3270626958069155}\n",
      "('딸기 바나나 사과 딸기 파인애플.', 0.3270626958069155)\n",
      "('파인애플 사과 딸기 바나나.', 0.3270626958069155)\n",
      "('바나나 사과 딸기.', 0.25134837504171265)\n"
     ]
    }
   ],
   "source": [
    "summary=summarize(Text, 3)\n",
    "\n",
    "for sent in summary :\n",
    "      print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 gensim을 활용한 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'과기정통부, 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입, 510'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_news_by_url(url):\n",
    "    res = requests.get(url)\n",
    "    bs = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "    title = bs.select('h3#articleTitle')[0].text #제목\n",
    "    content = bs.select('#articleBodyContents')[0].get_text().replace('\\n', \" \") #본문\n",
    "    content = content.replace(\"// flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}\", \"\")\n",
    "    return  content.strip()\n",
    "\n",
    "doc = get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=018&aid=0004430108')\n",
    "doc[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이를 통해 데이터 생태계를 혁신하고 기업의 경쟁력을 제고하는 역할을 수행한다',\n",
       " '주요 활용 전략·사례를 보면 빅데이터 활용을 통해 ‘신(新) 시장’을 창출하는 방안을 담고 있다',\n",
       " '\\n다양한 분석 도구는 물론 인공지능(AI) 학습 알고리즘도 제공해 이용자가 보다 사용하기 편리한 환경을 제공한다',\n",
       " '이밖에 필요한 데이터를 쉽게 등록하고 검색할 수 있도록 기준을 마련하고, 데이터 보유와 관리에 대한 체계(거버넌스)를 논의하는 ‘데이터 얼라이언스’를 구성해 보다 안전하게 이용하는 방안도 마련했다',\n",
       " '유영민 과기정통부 장관은 “오늘 출범식은 대한민국이 데이터 강국으로 가기 위한 초석을 놓은 자리”라며 “세계 주요국들보다 데이터 경제로 나아가는 발걸음이 다소 늦었지만, 빅데이터 플랫폼과 센터를 지렛대로 우리나라의 낙후된 데이터 생태계를 혁신하고 기업의 경쟁력을 한 단계 제고할 수 있도록 정책적 역량을 집중하겠다”고 밝혔다',\n",
       " '이재운 (jwlee@edaily',\n",
       " 'co',\n",
       " 'kr)네이버 홈에서 ‘이데일리’ 뉴스 [구독하기▶]꿀잼가득 [영상보기▶] , 청춘뉘우스~ [스냅타임▶]＜ⓒ종합 경제정보 미디어 이데일리 - 무단전재 & 재배포 금지＞']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "summarize(doc).split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
