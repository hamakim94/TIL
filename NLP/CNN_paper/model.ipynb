{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "import numpy as np\n",
    "import functions as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from tqdm import tqdm\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in tqdm(fin):\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data\n",
    "data = load_vectors('cc.ko.300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-356743ee24d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x2429f6c9438 state=finished returned list>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\YOON\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 808, in dispatch_one_batch\n",
      "    tasks = self._ready_batches.get(block=False)\n",
      "  File \"C:\\Users\\YOON\\anaconda3\\envs\\nlp\\lib\\queue.py\", line 161, in get\n",
      "    raise Empty\n",
      "queue.Empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\YOON\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\YOON\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 347, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\Users\\YOON\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 780, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"C:\\Users\\YOON\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 819, in dispatch_one_batch\n",
      "    islice = list(itertools.islice(iterator, big_batch_size))\n",
      "  File \"<ipython-input-7-85a388cde409>\", line 16, in <genexpr>\n",
      "    embeddings_index = dict(Parallel(n_jobs=-1)(delayed(loading)(line) for line in f))\n",
      "  File \"C:\\Users\\YOON\\anaconda3\\envs\\nlp\\lib\\codecs.py\", line 321, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xed in position 3486: invalid continuation byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173479\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    embeddings_index = {}\n",
    "\n",
    "    f = open(os.path.join('cc.ko.300.vec'), 'r', encoding='utf-8')\n",
    "    def loading(line):\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        return word, coefs\n",
    "\n",
    "    embeddings_index = dict(Parallel(n_jobs=-1)(delayed(loading)(line) for line in f))\n",
    "    f.close()\n",
    "    print(len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'짜증나다'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-37cf164f48d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0membeddings_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'짜증나다'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: '짜증나다'"
     ]
    }
   ],
   "source": [
    "embeddings_index['짜증나다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "df_train = pd.read_pickle('token_train_data.pkl')\n",
    "df_test = pd.read_pickle('token_test_data.pkl')\n",
    "\n",
    "token_train_data, train_lable = df_train['tokens'].values.tolist(), df_train['labels']\n",
    "token_test_data, test_lable = df_test['tokens'].values.tolist(), df_test['labels']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "45505\n"
     ]
    }
   ],
   "source": [
    "simple_ko_vec = {}\n",
    "oov_list=[]\n",
    "simple_ko_vec['<PAD/>'] = ko_model.wv.word_vec('<PAD/>')\n",
    "for sent in token_train_data+token_test_data:\n",
    "    for token in sent:\n",
    "        try:\n",
    "            simple_ko_vec[token] = ko_model.wv.word_vec(token)\n",
    "        except:\n",
    "            oov_list.append(token)\n",
    "oov_list= list(set(oov_list))\n",
    "print(len(oov_list))\n",
    "print(len(simple_ko_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요단어 선별하여 pickle에 딕셔너리 저장 (총 단어수 : 31604)\n",
    "import pickle\n",
    "with open('simple_ko_vec.pkl','wb') as fw:\n",
    "    pickle.dump(simple_ko_vec, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('simple_ko_vec.pkl','rb') as fw:\n",
    "    simple_w2v= pickle.load(fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('token_train_data.pkl')\n",
    "df_test = pd.read_pickle('token_test_data.pkl')\n",
    "token_train_data, train_lable = df_train['tokens'], df_train['labels']\n",
    "token_test_data, test_lable = df_test['tokens'], df_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sentences = fc.pad_sequence(token_train_data)\n",
    "paddedarray=[]\n",
    "for x in padded_sentences:\n",
    "    for token in x:\n",
    "        paddedarray.append(simple_w2v[token])\n",
    "# final_array = paddedarray.reshape(-1,max_len,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145791"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러들이는데 시간 오지게 걸리고? 별로 안걸리는데?, 다운 받아서 쥬피터 폴더에 넣어야함\n",
    "ko_model = models.fasttext.load_facebook_model('cc.ko.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt # 이걸 써서 포스 태깅을 할꺼고\n",
    "okt = Okt()\n",
    "import pandas as pd # 이것들 가져와\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장들 전처리하기\n",
    "def preprocessing(data):\n",
    "    data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    data = data.dropna(how = 'any')\n",
    "    data['document'] = data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "    data['document'].replace('', np.nan, inplace=True)\n",
    "    data = data.dropna(how = 'any')\n",
    "    sentences = data['document'].tolist()\n",
    "    label = data['label']\n",
    "    print('data len = {}'.format(len(sentences)))\n",
    "    return sentences, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 토큰화 하기\n",
    "def tokenize(sentence):\n",
    "    okt = Okt()\n",
    "    tokenized_sentence = []\n",
    "\n",
    "    # 우선 단어의 기본형으로 모두 살리고, 명사, 동사, 영어만 담는다.\n",
    "    # 그냥 nouns로 분리하는 것보다 좀 더 정확하고 많은 데이터를 얻을 수 있다.\n",
    "    for line in sentence:\n",
    "        result = []\n",
    "        temp_sentence = okt.pos(line, norm=True, stem=True) # 먼저 형태소 분리해서 리스트에 담고\n",
    "\n",
    "        for i in temp_sentence:                             \n",
    "            if (i[1] == 'Noun' or i[1] == 'Adjective' or i[1] == 'Alpha'):                  \n",
    "                result.append(i[0])\n",
    "            \n",
    "        tokenized_sentence.append(result)\n",
    "\n",
    "    return tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sentences, padding_word=\"<PAD/>\"): #  오른쪽을 패딩주기\n",
    "    maxlen = 40\n",
    "    padded_sentences = []\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        if len(sentence)<=maxlen:\n",
    "            num_padding = maxlen - len(sentence)\n",
    "            new_sentence = sentence + [padding_word] * num_padding\n",
    "        else : new_sentence = sentence[:maxlen]\n",
    "        padded_sentences.append(new_sentence)\n",
    "    return padded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ko_model.wv.word_vec('<PAD/>')\n",
    "paddedarray = np.array([ ko_model.wv.word_vec(token) for x in padded for token in x])\n",
    "final_array=paddedarray.reshape(-1,max_len,300) # 이런 형태네? max_length of sent = 22(34),근데 10개의 sent, 22*10 fasttext = 300(vector) \n",
    "final_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(padded_sentences):\n",
    "    paddedarray = np.array([ ko_model.wv.word_vec(token) for x in padded_sentences for token in x])\n",
    "    final_array=paddedarray.reshape(-1,max_len,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pre_train_data, train_label = preprocessing(train_data)\n",
    "pre_test_data, test_label = preprocessing(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_train_data = tokenize(pre_train_data)\n",
    "token_test_data = tokenize(pre_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len']=[len(i) for i in df['tokens']]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['len'].hist(bins =30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 토큰화된 데이터 pickle로 저장\n",
    "# import pandas as pd\n",
    "# import pickle\n",
    "# df = pd.DataFrame(np.array(token_test_data),columns=['tokens'])\n",
    "# df['labels']=list(map(int,test_label))\n",
    "# df2 = pd.DataFrame(token_test_data,test_label,columns=['tokens','lable'])\n",
    "# df1.to_pickle('token_train_data.pkl')\n",
    "# df2.to_pickle('token_test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "df_train = pd.read_pickle('token_train_data.pkl')\n",
    "df_test = pd.read_pickle('token_test_data.pkl')\n",
    "\n",
    "token_train_data, train_lable = df_train['tokens'], df_train['labels']\n",
    "token_test_data, test_lable = df_test['tokens'], df_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as fc\n",
    "max_len=30\n",
    "final_train_data = fc.fasttext_vectorize(fc.pad_sequence(token_train_data), max_len=max_len)\n",
    "final_test_data = fc.fasttext_vectorize(fc.pad_sequence(token_test_data), max_len=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "embedding_dim = 200\n",
    "filter_sizes = (3, 4, 5)\n",
    "num_filters = 100\n",
    "dropout = 0.5\n",
    "hidden_dims = 10\n",
    "\n",
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "min_word_count = 1\n",
    "context = 10\n",
    "\n",
    "conv_blocks = []\n",
    "\n",
    "sequence_length = 200\n",
    "\n",
    "# input_shape = (sequence_length, embedding_dim) # input shape for\n",
    "input_shape = (40, 300) # input shape for data, (max_length of sent, vect)\n",
    "\n",
    "model_input = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "z = model_input\n",
    "for sz in filter_sizes:\n",
    "    conv = keras.layers.Conv1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = keras.layers.MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = keras.layers.Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = keras.layers.Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "z = keras.layers.Dense(hidden_dims, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.003), bias_regularizer=keras.regularizers.l2(0.003))(z)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "model_output = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = keras.Model(model_input, model_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_dir = './ckpt1'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=0),\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the folder name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + '/ckpt-loss={loss:.3f}',\n",
    "        save_freq=500)\n",
    "]\n",
    "history = model.fit(final_train_data, train_lable, epochs=10, callbacks=callbacks, batch_size = batch_size, validation_data=(final_test_data, test_lable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_' + string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_' + string])\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.epoch = list(map(lambda x: x+25, history.epoch))\n",
    "history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'val_accuracy':[],'accuracy':[],'epoch':[],'loss':[],'val_loss':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.keys():\n",
    "    if i == 'epoch':\n",
    "        data['epoch'].extend(history.epoch)\n",
    "    else:\n",
    "        data[i].extend(history.history[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(data)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=pd.concat([new,b])\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.set_index('epoch', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graphs(data, string):\n",
    "  plt.plot(data[string])\n",
    "  plt.plot(data['val_' + string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_' + string])\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(new, 'accuracy')\n",
    "plot_graphs(new, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import tokenize, m2_load_token_and_label\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "\n",
    "oov_tok = '<OOV>'\n",
    "truct_type = 'post'\n",
    "padding_type = 'post'\n",
    "max_length = 30\n",
    "vocab_size =20000\n",
    "training_sentences, training_labels, testing_sentences, testing_labels = m2_load_token_and_label()\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_idx = tokenizer.index_word\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# test_sent=['재밌어요','재미 없어요']\n",
    "\n",
    "# test_sent = tokenize(test_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle','rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_sequences  = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, \n",
    "                                  padding=padding_type, truncating=truct_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences  = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, \n",
    "                                  padding=padding_type, truncating=truct_type)\n",
    "\n",
    "vocab_size = len(word_idx) + 1\n",
    "embedding_dim = 300\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "with open('simple_ko_vec.pkl','rb') as fw:\n",
    "    ko_model= pickle.load(fw)\n",
    "\n",
    "\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    embedding_vector = ko_model[word] if word in ko_model else None\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx] = embedding_vector\n",
    "\n",
    "#################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " '영화': 2,\n",
       " '없다': 3,\n",
       " '있다': 4,\n",
       " '좋다': 5,\n",
       " '재밌다': 6,\n",
       " '정말': 7,\n",
       " '것': 8,\n",
       " '같다': 9,\n",
       " '진짜': 10,\n",
       " '아니다': 11,\n",
       " '점': 12,\n",
       " '이': 13,\n",
       " '연기': 14,\n",
       " '평점': 15,\n",
       " '최고': 16,\n",
       " '왜': 17,\n",
       " '스토리': 18,\n",
       " '생각': 19,\n",
       " '드라마': 20,\n",
       " '감동': 21,\n",
       " '사람': 22,\n",
       " '보고': 23,\n",
       " '말': 24,\n",
       " '이렇다': 25,\n",
       " '아깝다': 26,\n",
       " '더': 27,\n",
       " '배우': 28,\n",
       " '때': 29,\n",
       " '감독': 30,\n",
       " '거': 31,\n",
       " '내': 32,\n",
       " '재미있다': 33,\n",
       " '뭐': 34,\n",
       " '시간': 35,\n",
       " '재미': 36,\n",
       " '내용': 37,\n",
       " '그냥': 38,\n",
       " '좀': 39,\n",
       " '그': 40,\n",
       " '지루하다': 41,\n",
       " '재미없다': 42,\n",
       " '쓰레기': 43,\n",
       " '수': 44,\n",
       " '그렇다': 45,\n",
       " '작품': 46,\n",
       " '사랑': 47,\n",
       " '나': 48,\n",
       " '하나': 49,\n",
       " '다시': 50,\n",
       " '마지막': 51,\n",
       " '볼': 52,\n",
       " '이다': 53,\n",
       " '정도': 54,\n",
       " '처음': 55,\n",
       " '완전': 56,\n",
       " '많다': 57,\n",
       " '장면': 58,\n",
       " '액션': 59,\n",
       " '주인공': 60,\n",
       " '안되다': 61,\n",
       " '돈': 62,\n",
       " '최악': 63,\n",
       " '이야기': 64,\n",
       " '지금': 65,\n",
       " '걸': 66,\n",
       " '느낌': 67,\n",
       " '연출': 68,\n",
       " '임': 69,\n",
       " '끝': 70,\n",
       " '듯': 71,\n",
       " '좋아하다': 72,\n",
       " '명작': 73,\n",
       " '별로': 74,\n",
       " '년': 75,\n",
       " '역시': 76,\n",
       " '개': 77,\n",
       " '이해': 78,\n",
       " '안': 79,\n",
       " '이영화': 80,\n",
       " '괜찮다': 81,\n",
       " '또': 82,\n",
       " '때문': 83,\n",
       " '여자': 84,\n",
       " '아름답다': 85,\n",
       " '꼭': 86,\n",
       " '보기': 87,\n",
       " '기억': 88,\n",
       " '결말': 89,\n",
       " '편': 90,\n",
       " '난': 91,\n",
       " '분': 92,\n",
       " '어떻다': 93,\n",
       " '중': 94,\n",
       " '아쉽다': 95,\n",
       " '인생': 96,\n",
       " '마음': 97,\n",
       " '소재': 98,\n",
       " '뻔하다': 99,\n",
       " '못': 100,\n",
       " '애': 101,\n",
       " '수준': 102,\n",
       " '무섭다': 103,\n",
       " '현실': 104,\n",
       " '한번': 105,\n",
       " '가장': 106,\n",
       " '반전': 107,\n",
       " '매력': 108,\n",
       " '전개': 109,\n",
       " '남자': 110,\n",
       " '한국': 111,\n",
       " '가슴': 112,\n",
       " '낮다': 113,\n",
       " '아이': 114,\n",
       " '슬프다': 115,\n",
       " '높다': 116,\n",
       " '유치하다': 117,\n",
       " '음악': 118,\n",
       " '알': 119,\n",
       " '멋지다': 120,\n",
       " '원작': 121,\n",
       " '저': 122,\n",
       " '줄': 123,\n",
       " '게': 124,\n",
       " '인간': 125,\n",
       " '솔직하다': 126,\n",
       " '우리': 127,\n",
       " '추천': 128,\n",
       " '눈물': 129,\n",
       " '무슨': 130,\n",
       " '만': 131,\n",
       " '속': 132,\n",
       " '함': 133,\n",
       " '자체': 134,\n",
       " '번': 135,\n",
       " '야하다': 136,\n",
       " '눈': 137,\n",
       " '짜증나다': 138,\n",
       " '코미디': 139,\n",
       " '캐릭터': 140,\n",
       " '대한': 141,\n",
       " '움': 142,\n",
       " '뭔가': 143,\n",
       " '이상': 144,\n",
       " '대박': 145,\n",
       " '전혀': 146,\n",
       " '이쁘다': 147,\n",
       " '도': 148,\n",
       " '연기력': 149,\n",
       " '여운': 150,\n",
       " '미치다': 151,\n",
       " '모두': 152,\n",
       " '개봉': 153,\n",
       " '공감': 154,\n",
       " '일본': 155,\n",
       " '기대': 156,\n",
       " '기대하다': 157,\n",
       " '시리즈': 158,\n",
       " '중간': 159,\n",
       " '영상': 160,\n",
       " '부분': 161,\n",
       " '아주': 162,\n",
       " '모습': 163,\n",
       " '귀엽다': 164,\n",
       " '제목': 165,\n",
       " '계속': 166,\n",
       " '가족': 167,\n",
       " '내내': 168,\n",
       " '전': 169,\n",
       " '보지': 170,\n",
       " '뿐': 171,\n",
       " '진심': 172,\n",
       " '다른': 173,\n",
       " '무엇': 174,\n",
       " '몰입': 175,\n",
       " '실망': 176,\n",
       " '표현': 177,\n",
       " '후': 178,\n",
       " '급': 179,\n",
       " '기분': 180,\n",
       " '대단하다': 181,\n",
       " '별': 182,\n",
       " '작가': 183,\n",
       " '잔잔하다': 184,\n",
       " '요': 185,\n",
       " '이제': 186,\n",
       " '위': 187,\n",
       " '요즘': 188,\n",
       " '공포': 189,\n",
       " '스릴러': 190,\n",
       " '감': 191,\n",
       " '긴장감': 192,\n",
       " '개인': 193,\n",
       " '용': 194,\n",
       " '모든': 195,\n",
       " '잼': 196,\n",
       " '조금': 197,\n",
       " '애니': 198,\n",
       " '대사': 199,\n",
       " '알바': 200,\n",
       " '이유': 201,\n",
       " '제대로': 202,\n",
       " '삶': 203,\n",
       " '극장': 204,\n",
       " '건': 205,\n",
       " '점도': 206,\n",
       " '노래': 207,\n",
       " '욕': 208,\n",
       " '굿': 209,\n",
       " '점수': 210,\n",
       " '시작': 211,\n",
       " '막장': 212,\n",
       " '나름': 213,\n",
       " '예쁘다': 214,\n",
       " '이상하다': 215,\n",
       " '깊다': 216,\n",
       " '제일': 217,\n",
       " '차라리': 218,\n",
       " '놈': 219,\n",
       " '친구': 220,\n",
       " '영화로': 221,\n",
       " '당시': 222,\n",
       " '노잼': 223,\n",
       " '어설프다': 224,\n",
       " '의미': 225,\n",
       " '절대': 226,\n",
       " '일': 227,\n",
       " '기': 228,\n",
       " '위해': 229,\n",
       " '류': 230,\n",
       " '세상': 231,\n",
       " '따뜻하다': 232,\n",
       " '미국': 233,\n",
       " '훌륭하다': 234,\n",
       " '공포영화': 235,\n",
       " '년대': 236,\n",
       " '도대체': 237,\n",
       " '웃음': 238,\n",
       " '제': 239,\n",
       " '설정': 240,\n",
       " '앞': 241,\n",
       " '짱': 242,\n",
       " '힘들다': 243,\n",
       " '초반': 244,\n",
       " '다르다': 245,\n",
       " '물': 246,\n",
       " '뭘': 247,\n",
       " '우리나라': 248,\n",
       " '출연': 249,\n",
       " '수작': 250,\n",
       " '해': 251,\n",
       " '싫다': 252,\n",
       " '답답하다': 253,\n",
       " '사실': 254,\n",
       " '추억': 255,\n",
       " '한국영': 256,\n",
       " '가지': 257,\n",
       " '멋있다': 258,\n",
       " '남': 259,\n",
       " '시나리오': 260,\n",
       " '신선하다': 261,\n",
       " '아프다': 262,\n",
       " '관객': 263,\n",
       " '소리': 264,\n",
       " '분위기': 265,\n",
       " '필요없다': 266,\n",
       " '로': 267,\n",
       " '팬': 268,\n",
       " '시대': 269,\n",
       " '장난': 270,\n",
       " '명': 271,\n",
       " '지루함': 272,\n",
       " '어이없다': 273,\n",
       " '나쁘다': 274,\n",
       " '살': 275,\n",
       " '자신': 276,\n",
       " '감정': 277,\n",
       " '졸작': 278,\n",
       " '엔딩': 279,\n",
       " '준': 280,\n",
       " '영화관': 281,\n",
       " '안타깝다': 282,\n",
       " '오늘': 283,\n",
       " '엄마': 284,\n",
       " '봄': 285,\n",
       " '제발': 286,\n",
       " '정신': 287,\n",
       " '접': 288,\n",
       " '인상': 289,\n",
       " '부족하다': 290,\n",
       " '스럽다': 291,\n",
       " '더럽다': 292,\n",
       " '더빙': 293,\n",
       " '포스터': 294,\n",
       " '캐스팅': 295,\n",
       " '최고다': 296,\n",
       " '라면': 297,\n",
       " '평가': 298,\n",
       " '문제': 299,\n",
       " '코믹': 300,\n",
       " '얼마나': 301,\n",
       " '애니메이션': 302,\n",
       " '어색하다': 303,\n",
       " '몰입도': 304,\n",
       " '티비': 305,\n",
       " '기도': 306,\n",
       " '배경': 307,\n",
       " '망하다': 308,\n",
       " '대해': 309,\n",
       " '유쾌하다': 310,\n",
       " '데': 311,\n",
       " '뒤': 312,\n",
       " '맘': 313,\n",
       " '킬링타임': 314,\n",
       " '음': 315,\n",
       " '스릴': 316,\n",
       " '만화': 317,\n",
       " '충격': 318,\n",
       " '얘기': 319,\n",
       " '완벽하다': 320,\n",
       " '전쟁': 321,\n",
       " '존나': 322,\n",
       " '진부하다': 323,\n",
       " '등': 324,\n",
       " '즐겁다': 325,\n",
       " '책': 326,\n",
       " '개연': 327,\n",
       " '예술': 328,\n",
       " '머리': 329,\n",
       " '갈수록': 330,\n",
       " '질': 331,\n",
       " '어디': 332,\n",
       " '얼굴': 333,\n",
       " '매우': 334,\n",
       " '웃기': 335,\n",
       " '머': 336,\n",
       " '후회': 337,\n",
       " '이름': 338,\n",
       " '영화인': 339,\n",
       " '옛날': 340,\n",
       " '구성': 341,\n",
       " '행복하다': 342,\n",
       " '적': 343,\n",
       " '집중': 344,\n",
       " '이후': 345,\n",
       " '장르': 346,\n",
       " '꽤': 347,\n",
       " '집': 348,\n",
       " '주연': 349,\n",
       " '의': 350,\n",
       " '새롭다': 351,\n",
       " '멀다': 352,\n",
       " '날': 353,\n",
       " '다큐': 354,\n",
       " '누구': 355,\n",
       " '시즌': 356,\n",
       " '상황': 357,\n",
       " '건가': 358,\n",
       " '그것': 359,\n",
       " '언제': 360,\n",
       " '짜증': 361,\n",
       " '억지': 362,\n",
       " '씬': 363,\n",
       " '예전': 364,\n",
       " '충분하다': 365,\n",
       " '글': 366,\n",
       " '후반': 367,\n",
       " '비': 368,\n",
       " '역사': 369,\n",
       " '다운': 370,\n",
       " '강추': 371,\n",
       " '걸작': 372,\n",
       " '궁금하다': 373,\n",
       " '불쌍하다': 374,\n",
       " '여기': 375,\n",
       " '누가': 376,\n",
       " '진': 377,\n",
       " '약간': 378,\n",
       " '자기': 379,\n",
       " '두': 380,\n",
       " '소름': 381,\n",
       " '인물': 382,\n",
       " '실화': 383,\n",
       " '해도': 384,\n",
       " '발연기': 385,\n",
       " '그대로': 386,\n",
       " '밉다': 387,\n",
       " '방송': 388,\n",
       " '심하다': 389,\n",
       " '시절': 390,\n",
       " '만점': 391,\n",
       " '잔인하다': 392,\n",
       " '회': 393,\n",
       " '비디오': 394,\n",
       " '대체': 395,\n",
       " '순수하다': 396,\n",
       " '비슷하다': 397,\n",
       " '작': 398,\n",
       " '어렵다': 399,\n",
       " '니': 400,\n",
       " '소설': 401,\n",
       " '한마디': 402,\n",
       " '로맨스': 403,\n",
       " '사회': 404,\n",
       " '아들': 405,\n",
       " '부': 406,\n",
       " '비교': 407,\n",
       " '필요하다': 408,\n",
       " '초딩': 409,\n",
       " '감성': 410,\n",
       " '판': 411,\n",
       " '네이버': 412,\n",
       " '다음': 413,\n",
       " '를': 414,\n",
       " '보': 415,\n",
       " '여배우': 416,\n",
       " '여주': 417,\n",
       " '전체': 418,\n",
       " '간만': 419,\n",
       " '상당하다': 420,\n",
       " '편이': 421,\n",
       " '나이': 422,\n",
       " '사랑스럽다': 423,\n",
       " '당하다': 424,\n",
       " '꿈': 425,\n",
       " '코': 426,\n",
       " '성룡': 427,\n",
       " '굉장하다': 428,\n",
       " '동안': 429,\n",
       " '혼자': 430,\n",
       " '순간': 431,\n",
       " '교훈': 432,\n",
       " '삼류': 433,\n",
       " '은': 434,\n",
       " '존재': 435,\n",
       " '힘': 436,\n",
       " '바로': 437,\n",
       " '주제': 438,\n",
       " '진정하다': 439,\n",
       " '목소리': 440,\n",
       " '년도': 441,\n",
       " '안보': 442,\n",
       " '화려하다': 443,\n",
       " '죽': 444,\n",
       " '당신': 445,\n",
       " '거의': 446,\n",
       " '너': 447,\n",
       " '몇번': 448,\n",
       " '낭비': 449,\n",
       " '가볍다': 450,\n",
       " '년전': 451,\n",
       " '질질': 452,\n",
       " '독특하다': 453,\n",
       " '나라': 454,\n",
       " '엄청나다': 455,\n",
       " '줄거리': 456,\n",
       " '성하다': 457,\n",
       " '자': 458,\n",
       " '의도': 459,\n",
       " '딸': 460,\n",
       " '아버지': 461,\n",
       " '좀비': 462,\n",
       " '판타지': 463,\n",
       " '이번': 464,\n",
       " '갑자기': 465,\n",
       " '어른': 466,\n",
       " '전부': 467,\n",
       " '점주': 468,\n",
       " '상영': 469,\n",
       " '시청률': 470,\n",
       " '흥미롭다': 471,\n",
       " '피': 472,\n",
       " '실제': 473,\n",
       " '넘치다': 474,\n",
       " '신': 475,\n",
       " '평론가': 476,\n",
       " '곳': 477,\n",
       " '맛': 478,\n",
       " '만하': 479,\n",
       " '재': 480,\n",
       " '필요': 481,\n",
       " '땜': 482,\n",
       " '제작': 483,\n",
       " '막': 484,\n",
       " '바': 485,\n",
       " '점점': 486,\n",
       " '한편': 487,\n",
       " '그녀': 488,\n",
       " '화면': 489,\n",
       " '극장판': 490,\n",
       " '초': 491,\n",
       " '중국': 492,\n",
       " '답': 493,\n",
       " '각본': 494,\n",
       " '간다': 495,\n",
       " '볼때': 496,\n",
       " '억지스럽다': 497,\n",
       " '밑': 498,\n",
       " '평': 499,\n",
       " '관람': 500,\n",
       " '이하': 501,\n",
       " '스타일': 502,\n",
       " '란': 503,\n",
       " '세계': 504,\n",
       " '선택': 505,\n",
       " '선': 506,\n",
       " '성우': 507,\n",
       " '요소': 508,\n",
       " '복수': 509,\n",
       " '항상': 510,\n",
       " '일단': 511,\n",
       " '굳다': 512,\n",
       " '둘': 513,\n",
       " '똥': 514,\n",
       " '가치': 515,\n",
       " '뻔': 516,\n",
       " '흥행': 517,\n",
       " '힘드다': 518,\n",
       " '너무하다': 519,\n",
       " '참고': 520,\n",
       " '그때': 521,\n",
       " '더욱': 522,\n",
       " '확실하다': 523,\n",
       " '영': 524,\n",
       " '드': 525,\n",
       " '불편하다': 526,\n",
       " '면': 527,\n",
       " '아빠': 528,\n",
       " '평범하다': 529,\n",
       " '수가': 530,\n",
       " '역대': 531,\n",
       " '거기': 532,\n",
       " '발': 533,\n",
       " '완성': 534,\n",
       " '편집': 535,\n",
       " '단순하다': 536,\n",
       " '상미': 537,\n",
       " '전형': 538,\n",
       " '멜로': 539,\n",
       " '허무하다': 540,\n",
       " '거지': 541,\n",
       " '새끼': 542,\n",
       " '짧다': 543,\n",
       " '세': 544,\n",
       " '화이팅': 545,\n",
       " '역': 546,\n",
       " '어이': 547,\n",
       " '술': 548,\n",
       " '탄탄하다': 549,\n",
       " '진행': 550,\n",
       " '불륜': 551,\n",
       " '구': 552,\n",
       " '엉망': 553,\n",
       " '예상': 554,\n",
       " '병맛': 555,\n",
       " '개그': 556,\n",
       " '잠': 557,\n",
       " '사건': 558,\n",
       " '낫다': 559,\n",
       " '중반': 560,\n",
       " '지겹다': 561,\n",
       " '미화': 562,\n",
       " '소중하다': 563,\n",
       " '그게': 564,\n",
       " '설명': 565,\n",
       " '똑같다': 566,\n",
       " '과거': 567,\n",
       " '또한': 568,\n",
       " '키': 569,\n",
       " '적당하다': 570,\n",
       " '프랑스': 571,\n",
       " '중요하다': 572,\n",
       " '화보': 573,\n",
       " '꿀잼': 574,\n",
       " '훈훈하다': 575,\n",
       " '봣': 576,\n",
       " '도저히': 577,\n",
       " '손': 578,\n",
       " '노력': 579,\n",
       " '흥미진진': 580,\n",
       " '몇': 581,\n",
       " '댓글': 582,\n",
       " '그래픽': 583,\n",
       " '흥미': 584,\n",
       " '거리': 585,\n",
       " '죽음': 586,\n",
       " '원래': 587,\n",
       " '취향': 588,\n",
       " '티': 589,\n",
       " '무조건': 590,\n",
       " '몸': 591,\n",
       " '리': 592,\n",
       " '식상하다': 593,\n",
       " '척': 594,\n",
       " '화가': 595,\n",
       " '뛰어나다': 596,\n",
       " '마르다': 597,\n",
       " '자극': 598,\n",
       " '역겹다': 599,\n",
       " '배': 600,\n",
       " '감상': 601,\n",
       " '울': 602,\n",
       " '한심하다': 603,\n",
       " '학교': 604,\n",
       " '길다': 605,\n",
       " '자꾸': 606,\n",
       " '액션영화': 607,\n",
       " '관': 608,\n",
       " '아저씨': 609,\n",
       " '예고편': 610,\n",
       " '오히려': 611,\n",
       " '바보': 612,\n",
       " '결혼': 613,\n",
       " '심리': 614,\n",
       " '용도': 615,\n",
       " '다가': 616,\n",
       " '속편': 617,\n",
       " '게임': 618,\n",
       " '연기자': 619,\n",
       " '보이': 620,\n",
       " '마무리': 621,\n",
       " '터': 622,\n",
       " '무': 623,\n",
       " '잘만': 624,\n",
       " '강하다': 625,\n",
       " '관계': 626,\n",
       " '천재': 627,\n",
       " '법': 628,\n",
       " '미안하다': 629,\n",
       " '참신하다': 630,\n",
       " '억지로': 631,\n",
       " '표정': 632,\n",
       " '아무': 633,\n",
       " '과': 634,\n",
       " '귀신': 635,\n",
       " '땐': 636,\n",
       " '최근': 637,\n",
       " '전설': 638,\n",
       " '현재': 639,\n",
       " '상상': 640,\n",
       " '유치': 641,\n",
       " '촬영': 642,\n",
       " '산': 643,\n",
       " '대한민국': 644,\n",
       " '타임': 645,\n",
       " '아쉬움': 646,\n",
       " '시': 647,\n",
       " '젠': 648,\n",
       " '짓': 649,\n",
       " '식': 650,\n",
       " '짐': 651,\n",
       " '전편': 652,\n",
       " '길': 653,\n",
       " '스타': 654,\n",
       " '묘사': 655,\n",
       " '대작': 656,\n",
       " '메세지': 657,\n",
       " '진지하다': 658,\n",
       " '열': 659,\n",
       " '철학': 660,\n",
       " '작다': 661,\n",
       " '프로': 662,\n",
       " '총': 663,\n",
       " '프로그램': 664,\n",
       " '동화': 665,\n",
       " '그림': 666,\n",
       " '마': 667,\n",
       " '드럽다': 668,\n",
       " '여전하다': 669,\n",
       " '졸라': 670,\n",
       " '전달': 671,\n",
       " '서로': 672,\n",
       " '역할': 673,\n",
       " '실망하다': 674,\n",
       " '유머': 675,\n",
       " '등장': 676,\n",
       " '조연': 677,\n",
       " '전작': 678,\n",
       " '경찰': 679,\n",
       " '나중': 680,\n",
       " '무비': 681,\n",
       " '다행': 682,\n",
       " '소녀': 683,\n",
       " '여': 684,\n",
       " '먼저': 685,\n",
       " '마치': 686,\n",
       " '멍청하다': 687,\n",
       " '살인': 688,\n",
       " '영원하다': 689,\n",
       " '고': 690,\n",
       " '덥다': 691,\n",
       " '흠': 692,\n",
       " '잘생기다': 693,\n",
       " '흔하다': 694,\n",
       " '오': 695,\n",
       " '특유': 696,\n",
       " '약하다': 697,\n",
       " '행동': 698,\n",
       " '환상': 699,\n",
       " '햇': 700,\n",
       " '저런': 701,\n",
       " '통해': 702,\n",
       " '인정': 703,\n",
       " '런가': 704,\n",
       " '노출': 705,\n",
       " '관심': 706,\n",
       " '주의': 707,\n",
       " '지루': 708,\n",
       " '입': 709,\n",
       " '청춘': 710,\n",
       " '군대': 711,\n",
       " '바람': 712,\n",
       " '노': 713,\n",
       " '착하다': 714,\n",
       " '예산': 715,\n",
       " '리메이크': 716,\n",
       " '낚': 717,\n",
       " '황당하다': 718,\n",
       " '정': 719,\n",
       " '미래': 720,\n",
       " '안나': 721,\n",
       " '깊이': 722,\n",
       " '가능하다': 723,\n",
       " '씨': 724,\n",
       " '제작비': 725,\n",
       " '위대하다': 726,\n",
       " '효과': 727,\n",
       " '망작': 728,\n",
       " '영웅': 729,\n",
       " '그닥': 730,\n",
       " '손발': 731,\n",
       " '생애': 732,\n",
       " '인하다': 733,\n",
       " '시도': 734,\n",
       " '외': 735,\n",
       " '케이블': 736,\n",
       " '평생': 737,\n",
       " '다만': 738,\n",
       " '과정': 739,\n",
       " '반': 740,\n",
       " '반개': 741,\n",
       " '용이': 742,\n",
       " '유명하다': 743,\n",
       " '범인': 744,\n",
       " '온': 745,\n",
       " '희망': 746,\n",
       " '형님': 747,\n",
       " '젊다': 748,\n",
       " '채널': 749,\n",
       " '얼': 750,\n",
       " '미소': 751,\n",
       " '잘못': 752,\n",
       " '가끔': 753,\n",
       " '화': 754,\n",
       " '강': 755,\n",
       " '상상력': 756,\n",
       " '능력': 757,\n",
       " '스케일': 758,\n",
       " '다소': 759,\n",
       " '모': 760,\n",
       " '신기하다': 761,\n",
       " '카메라': 762,\n",
       " '존': 763,\n",
       " '결론': 764,\n",
       " '부터': 765,\n",
       " '광고': 766,\n",
       " '설레다': 767,\n",
       " '독립영화': 768,\n",
       " '대충': 769,\n",
       " '생': 770,\n",
       " '단': 771,\n",
       " '자막': 772,\n",
       " '메시지': 773,\n",
       " '대안': 774,\n",
       " '한계': 775,\n",
       " '체': 776,\n",
       " '고민': 777,\n",
       " '슬픔': 778,\n",
       " '고맙다': 779,\n",
       " '부족': 780,\n",
       " '고생': 781,\n",
       " '빠르다': 782,\n",
       " '여성': 783,\n",
       " '네': 784,\n",
       " '원하다': 785,\n",
       " '변하다': 786,\n",
       " '리얼': 787,\n",
       " '줌': 788,\n",
       " '커플': 789,\n",
       " '산만하다': 790,\n",
       " '동생': 791,\n",
       " '이면': 792,\n",
       " '지난': 793,\n",
       " '어린이': 794,\n",
       " '사이': 795,\n",
       " '방': 796,\n",
       " '리뷰': 797,\n",
       " '거지같다': 798,\n",
       " '박수': 799,\n",
       " '아침': 800,\n",
       " '보시': 801,\n",
       " '차': 802,\n",
       " '유': 803,\n",
       " '시청자': 804,\n",
       " '괴물': 805,\n",
       " '자연': 806,\n",
       " '희다': 807,\n",
       " '살짝': 808,\n",
       " '굳이': 809,\n",
       " '흐름': 810,\n",
       " '로맨틱': 811,\n",
       " '짱짱': 812,\n",
       " '범죄': 813,\n",
       " '밤': 814,\n",
       " '폭력': 815,\n",
       " '연애': 816,\n",
       " '개판': 817,\n",
       " '포장': 818,\n",
       " '게이': 819,\n",
       " '발견': 820,\n",
       " '심심하다': 821,\n",
       " '빨': 822,\n",
       " '진정': 823,\n",
       " '영환': 824,\n",
       " '수도': 825,\n",
       " '악역': 826,\n",
       " '왠만하다': 827,\n",
       " '몸매': 828,\n",
       " '멋': 829,\n",
       " '어찌': 830,\n",
       " '주기': 831,\n",
       " '덕분': 832,\n",
       " '혹시': 833,\n",
       " '포기': 834,\n",
       " '달': 835,\n",
       " '감탄': 836,\n",
       " '진실': 837,\n",
       " '표절': 838,\n",
       " '일상': 839,\n",
       " '시선': 840,\n",
       " '쓰래': 841,\n",
       " '사극': 842,\n",
       " '조폭': 843,\n",
       " '치': 844,\n",
       " '인기': 845,\n",
       " '웬만하다': 846,\n",
       " '랄': 847,\n",
       " '문화': 848,\n",
       " '정서': 849,\n",
       " '성인': 850,\n",
       " '우정': 851,\n",
       " '표': 852,\n",
       " '대의': 853,\n",
       " '과연': 854,\n",
       " '젤': 855,\n",
       " '남녀': 856,\n",
       " '우울하다': 857,\n",
       " '상처': 858,\n",
       " '더하다': 859,\n",
       " '깔끔하다': 860,\n",
       " '뜻': 861,\n",
       " '퀄리티': 862,\n",
       " '암': 863,\n",
       " '쩐다': 864,\n",
       " '불': 865,\n",
       " '끼리': 866,\n",
       " '로서': 867,\n",
       " '유일하다': 868,\n",
       " '홍콩': 869,\n",
       " '성도': 870,\n",
       " '스': 871,\n",
       " '용서': 872,\n",
       " '특별하다': 873,\n",
       " '순': 874,\n",
       " '오락': 875,\n",
       " '심': 876,\n",
       " '이연걸': 877,\n",
       " '죄': 878,\n",
       " '막판': 879,\n",
       " '하루': 880,\n",
       " '코드': 881,\n",
       " '홍보': 882,\n",
       " '크게': 883,\n",
       " '볼거리': 884,\n",
       " '섹스': 885,\n",
       " '말로': 886,\n",
       " '뮤지컬': 887,\n",
       " '국민': 888,\n",
       " '일이': 889,\n",
       " '정치': 890,\n",
       " '보라': 891,\n",
       " '이기': 892,\n",
       " '어제': 893,\n",
       " '간': 894,\n",
       " '느와르': 895,\n",
       " '빛': 896,\n",
       " '싫어하다': 897,\n",
       " '난해하다': 898,\n",
       " '만큼': 899,\n",
       " '등장인물': 900,\n",
       " '원': 901,\n",
       " '해피엔딩': 902,\n",
       " '북한': 903,\n",
       " '보아': 904,\n",
       " '핵': 905,\n",
       " '펑펑': 906,\n",
       " '힐링': 907,\n",
       " '자식': 908,\n",
       " '희생': 909,\n",
       " '첨': 910,\n",
       " '무협': 911,\n",
       " '나머지': 912,\n",
       " '감명': 913,\n",
       " '끌': 914,\n",
       " '형편': 915,\n",
       " '첫': 916,\n",
       " '지도': 917,\n",
       " '눈빛': 918,\n",
       " '반성': 919,\n",
       " '불가': 920,\n",
       " '무겁다': 921,\n",
       " '자유': 922,\n",
       " '남편': 923,\n",
       " '본방': 924,\n",
       " '당연하다': 925,\n",
       " '다큐멘터리': 926,\n",
       " '딱하다': 927,\n",
       " '차이': 928,\n",
       " '춤': 929,\n",
       " '공부': 930,\n",
       " '기술': 931,\n",
       " '개도': 932,\n",
       " '안좋다': 933,\n",
       " '불쾌하다': 934,\n",
       " '뜬금': 935,\n",
       " '열정': 936,\n",
       " '행복': 937,\n",
       " '실감': 938,\n",
       " '올해': 939,\n",
       " '소장': 940,\n",
       " '늘': 941,\n",
       " '기본': 942,\n",
       " '싸움': 943,\n",
       " '노답': 944,\n",
       " '대화': 945,\n",
       " '쫌': 946,\n",
       " '제로': 947,\n",
       " '의문': 948,\n",
       " '입장': 949,\n",
       " '기적': 950,\n",
       " '무시': 951,\n",
       " '비극': 952,\n",
       " '찡하다': 953,\n",
       " '비주': 954,\n",
       " '불구': 955,\n",
       " '뭐임': 956,\n",
       " '따위': 957,\n",
       " '가면': 958,\n",
       " '느리다': 959,\n",
       " '종교': 960,\n",
       " '그다지': 961,\n",
       " '디즈니': 962,\n",
       " '긴장': 963,\n",
       " '색다르다': 964,\n",
       " '싸구려': 965,\n",
       " '지구': 966,\n",
       " '좀더': 967,\n",
       " '결과': 968,\n",
       " '시사회': 969,\n",
       " '실력': 970,\n",
       " '대가': 971,\n",
       " '악당': 972,\n",
       " '호러': 973,\n",
       " '부끄럽다': 974,\n",
       " '아픔': 975,\n",
       " '아줌마': 976,\n",
       " '적절하다': 977,\n",
       " '게다가': 978,\n",
       " '이제야': 979,\n",
       " '동물': 980,\n",
       " '반복': 981,\n",
       " '본인': 982,\n",
       " '촌스럽다': 983,\n",
       " '강렬하다': 984,\n",
       " '아련하다': 985,\n",
       " '인지': 986,\n",
       " '발전': 987,\n",
       " '러닝': 988,\n",
       " '완전하다': 989,\n",
       " '밥': 990,\n",
       " '방금': 991,\n",
       " '아이돌': 992,\n",
       " '단지': 993,\n",
       " '존경': 994,\n",
       " '하하': 995,\n",
       " '빡치다': 996,\n",
       " '짠하다': 997,\n",
       " '분노': 998,\n",
       " '여행': 999,\n",
       " '인': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40015"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sizes = (3, 4, 5)\n",
    "num_filters = 100\n",
    "dropout = 0.5\n",
    "hidden_dims = 100\n",
    "max_length = 30\n",
    "\n",
    "conv_blocks =[]\n",
    "input_shape = (max_length)\n",
    "\n",
    "model_input = keras.layers.Input(shape=input_shape)\n",
    "z = model_input\n",
    "\n",
    "\n",
    "for sz in filter_sizes:\n",
    "    embedding = keras.layers.Embedding(embedding_matrix.shape[0],embedding_matrix.shape[1],input_length=max_length,\n",
    "                                      weights =[embedding_matrix], trainable = False)(z)\n",
    "    conv = keras.layers.Conv1D(filters=num_filters,\n",
    "                      kernel_size=sz,\n",
    "                      padding=\"valid\",\n",
    "                      activation=\"relu\",\n",
    "                      strides=1)(embedding)\n",
    "    conv = keras.layers.GlobalAveragePooling1D()(conv)\n",
    "    conv = keras.layers.Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = keras.layers.Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = keras.layers.Dense(hidden_dims, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.003), bias_regularizer=keras.regularizers.l2(0.003))(z)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "model_output = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "model = keras.Model(model_input, model_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2915/2916 [============================>.] - ETA: 0s - loss: 0.5042 - accuracy: 0.7731INFO:tensorflow:Assets written to: ./ckpt1\\ckpt-loss=0.504\\assets\n",
      "2916/2916 [==============================] - 37s 13ms/step - loss: 0.5042 - accuracy: 0.7731 - val_loss: 0.4516 - val_accuracy: 0.7960\n",
      "Epoch 2/10\n",
      "2916/2916 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.8066INFO:tensorflow:Assets written to: ./ckpt1\\ckpt-loss=0.437\\assets\n",
      "2916/2916 [==============================] - 37s 13ms/step - loss: 0.4368 - accuracy: 0.8066 - val_loss: 0.4300 - val_accuracy: 0.8086\n",
      "Epoch 3/10\n",
      "2915/2916 [============================>.] - ETA: 0s - loss: 0.4090 - accuracy: 0.8232INFO:tensorflow:Assets written to: ./ckpt1\\ckpt-loss=0.409\\assets\n",
      "2916/2916 [==============================] - 37s 13ms/step - loss: 0.4089 - accuracy: 0.8232 - val_loss: 0.4185 - val_accuracy: 0.8155\n",
      "Epoch 4/10\n",
      "2913/2916 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8379INFO:tensorflow:Assets written to: ./ckpt1\\ckpt-loss=0.385\\assets\n",
      "2916/2916 [==============================] - 38s 13ms/step - loss: 0.3852 - accuracy: 0.8379 - val_loss: 0.4158 - val_accuracy: 0.8177\n",
      "Epoch 5/10\n",
      "2915/2916 [============================>.] - ETA: 0s - loss: 0.3622 - accuracy: 0.8517INFO:tensorflow:Assets written to: ./ckpt1\\ckpt-loss=0.362\\assets\n",
      "2916/2916 [==============================] - 39s 13ms/step - loss: 0.3622 - accuracy: 0.8517 - val_loss: 0.4155 - val_accuracy: 0.8193\n",
      "Epoch 6/10\n",
      "2916/2916 [==============================] - 37s 13ms/step - loss: 0.3374 - accuracy: 0.8664 - val_loss: 0.4477 - val_accuracy: 0.8127\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "import os #폴더 생성\n",
    "checkpoint_dir = './ckpt1'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=0),\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the folder name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + '/ckpt-loss={loss:.3f}',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True)\n",
    "]\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, callbacks=callbacks, batch_size = batch_size, validation_data=(testing_padded, testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['재밌다'], ['재미', '없다']]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    i+=1\n",
    "    yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    i=1\n",
    "    yield i * 3\n",
    "    \n",
    "    yield i* 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(next(gen()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(next(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
