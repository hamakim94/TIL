by ysubg 1gram - 5gram  -> we can consider the context

(Lower unemplyment, sluggish recovery)



in order to distunguish certain language, we're going to use 2 kinds of sentiment indicators

- marketing approach
  - pros : do not rely on the researcher's subjecteive selection of seed words
    -  use only market informations
  - cons: naturally produce statistically significant outcomes
- lexical approach
  - pros : polarity based on proximity(근접)  to the pre-determined seed words



So we use state-ofthe-art domain-specific sentiment induction algorithm

'SentProp'



'eKoNLPy'



previous : frequency //// rely more on tones/sentiments





!!방법론!!



네이버 따로 인포맥스 따로

We collect *231,699 documents for the period of May 2005–December
2017, which include 151 minutes of MPB meetings, 206,223 news
articles, and 26,284 bond analyst reports. Table 2 shows the types and
numbers of documents and the average and maximum number of
sentences. While our target texts are the MPB minutes, we use a large
amount of other documents to build field-specific lexicons.



##  News Articles

January 2005 to December 2017.8)

The number of news articles for our final use is 206,223. Among them, 42% (86,538) are from Yonhab Infomax, 33% (68,728) from EDAILY, and 25% (50,957) from Yonhab News.

연합 인포맥스 따로

네이버 따로

## 1.3 Bond Analysts’Reports

WIEfn, https://www.wisereport.co.kr/

corpus : we extract using
Latent Dirichlet Allocation (LDA) method, a topic modeling method. Table

# 2. Pre-processing Texts

## 2.1 Typical Steps of Pre-Processing

tokenize -> pos tag -> 

normalize ->  reomoving punctuation, stop words removal, converting numbers to their wordequivalents, stemming, lemmatization, and case folding.10)



## 2.2 Korean NLP Python Library for Economic Analysis (eKoNLPy)

1. use eKoNLPy

4. we use lemmatizition ( reason)



# 3. Feature Selection

To address this trade-off, we set the n of n-gram to 5 with additional
rules.

1. (NNG), adjectives (VA, VAX), adverbs (MAG), verbs (VA), and negations.17)
2. also drop n-grams that occur less frequently than 15 times.18)



result : 

The final word set is comprised of 2,712 words and we obtain the
resulting 73,428 n-grams.

using 1 gram to 5 gram



# 4. Polarity Classification

## 1st issue : supervise vs unsupervised

supervised : Google Cloud Sentiment Analysis API

unsupervised : PMI (Pointwise Mutual Information)

## 2nd issue : machine-learning-based vs. lexical-based

1. market approach that classifies polarity from market information using machine learning
2. corpus-based approach that classifies polarity using word(ngram) embedding seed words -> lexical



### MARKET APPROACH

For our market approach, we use the Na ̈ıve Bayes classifier (NBC),

we label news articles and reports in our corpus as hawkish (dovish) if the
1-month change of Call rates is positive (negative) on the day they are
released.25)

training set and a test set by 9:1 ratio.26)

we repeat this procedure 30 times and use the
average of the polarity scores as a final one.

We classify the polarity of our lexicon as hawkish (dovish) if the
polarity score is greater (less) than 1, excluding lexicon in the grey area
using intensity of 1.3 as a threshold.30) The final number of lexicon is
18,685 for hawkish and 21,280 for dovish. A sample of polarity lexicon is
provided in table 4.



### Lexical Approach

main idea : if two words appear together frequently in the same context, they are likely to have the same polarity. Then the polarity of an unknown word can be determined
by calculating the relative frequency of co-occurrence with another word.



1. PMI (Pointwise Mutual Information).

2. SO-PMI (Semantic Orientation from PMI)



cons:

- fails to recognize antonyms because it judges the polarity based on co-occurrence.
  - -> we use ngram2vec by Zhao, Liu, Li, Li, and Du (2017) instead of word embedding.
- Second, the outcome is affected by choices of seed words.
  - SentProp framework by Hamilton et al.
  - addresses this issue by bootstrapping seed words.



ngram2vec 

 too many(344,293 unique n-grams with a minimum frequency limit of 25, which yield 410,902,512 pairs of n-grams (21.7 GB in size).)... 

so we bootstrap by running our propagation 50times over 10 random equally sized subsets of  hawkish and dovish seed sets

--- determination : polarity score is greater (less) than 1,

excluding lexicon in the grey area using intensity of 1.1 as a threshold.



## 4.3, Evaluation

the BOK Governor’s news conference about monetary policy decisions.

May 2009 to January 2018,

we manually label 2,341 sentences as hawkish, neutral, and dovish.

- we train a Na ̈ıve Bayes classifier with randomly selected
  60% of hawkish and dovish sentences
- test with the remaining
  sentences.



With 30 times of iteration, the average accuracy of classifiers is
about 86%, which we think is above par accuracy.



# Measuring Sentiments (tones)

2 step approach

we calculate the tone of a sentence based on the
number of hawkish and dovish features (n-grams) in each sentence.



whole tone -> define tone of document

수식

creates a continuous variable  for each document, which is
bound between −1 (dovish) and +1 (hawkish).33)



1.  Can our lexicon-based indicators (tone(mkt) and tone(lex) explain the
   BOK’s current and future monetary policy decisions? In particular,
   do they have additional information that are not available in the
   existing macroeconomic data?
   - yes!
   - 

2. Is it important to use a field-specific dictionary?
3. Is it important to use the original Korean text, not Korean-to-English
   text?



