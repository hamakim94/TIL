{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어 임베딩(Word Embedding)\n",
    "- 단어 숫자 표현  \n",
    "    - 원핫 인코딩(제일 간단한 방법) : 차원 커져, 의미 못답아, 나빠,\n",
    "    - 밀집벡터로 해결\n",
    "        - 분포 가설 '같은 문맥에서 등장하는 단어는 유사한 의미를 지닌다' -> 같은 문맥에 등장하면 가까이 표현~\n",
    "        \n",
    "# NPLM 9 a neural probabilistic language model(논문\n",
    "- 논문의 의의\n",
    "\n",
    "단어의 벡터화라는 개념 도입  \n",
    "단어 시퀸스가 주어졌을 때 다음 단어가 무엇인지 맞추는 과정  \n",
    "\n",
    "- 한계\n",
    "\n",
    "몇개의 단어를 볼지 정해줘야 함  \n",
    "이전 단어들만 신경 쓸 수 있고, 현재 보고있는 앞 단어들은 고려하지 못한다  \n",
    "느 리 다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec \n",
    "- 단어를 원자 단위로 보기 때문에 단어간 유사성에 대한 고려가 없음\n",
    "- 유사단어 간에는 거리가 가까운 경항이 있고, 단어는 다양한 유사도를 가진다\n",
    "- King - Man + Woman = Queen ( 미쳤네.. )\n",
    "\n",
    "## 용어정리\n",
    "- 주변단어를 통해 중심단어를 예측 / 중심 단어를 통해 주변 단어를 예측\n",
    "    - slicing 해서 window 만들어줌, 윈도우 사이즈가 1이면 총 3개(앞,뒤 단어 포함)\n",
    "    - 중심단어 가운데 , 몇 개를 주변으로 할래가 윈도우 사이즈인듯!\n",
    "    \n",
    "## Continuous BOW Model\n",
    "- I want () food tonight <- 괄호 안에 들어갈 말을 휸련시킴..\n",
    "\n",
    "- 왼쪽부터 끝까지 window만큼 주변을 다 넣어버림, 줌심단어 기준 주변 단어들을 다 넣어준다.\n",
    "- One-hot 으로 넣어줘\n",
    "- 투사층으로 차원을 축소해서 Dense하게 만들어줘\n",
    "- 이를 다시 v 차원으로 (단어 list) 만들어서 softmax 취해준다\n",
    "- 다항 분포니까, softmax를 취해서 뭘 넣을지 정해준다.(argmax를 통해서 가장 확률 높은거 뽑아)\n",
    "## Skip-gram Model\n",
    "\n",
    "- 중심 단어를 주고, 주변 단어를 예측하는 거 \n",
    "- 근데 전체 단어를 고려하니까 계산 량이 엄청나게 많아져\n",
    "\n",
    "## skip gram with Neagative Sampling\n",
    "- 윈도우 안에 있으면 positive, 윈도우 밖에 있으면 negative\n",
    "- 전체 단어가 아니라 일부 단어를 뽑아서 계산\n",
    "- 윈도우 내 등장하지 않은 단어 wi가 negative로 뽑힐 확률 이런식으로 계산한다~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_news =  pd.read_csv('C:/Users/User/Desktop/news.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>media</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>연합인포맥스</td>\n",
       "      <td>내년 美국채수익률 5% 넘어서기 어려울 듯</td>\n",
       "      <td>2005년 10년만기 미국 국채수익률이  연방준비제도이사회(FRB)의 금리인상 지속...</td>\n",
       "      <td>만기/NNG,국채/NNG,수익률/NNG,fed/NNG,fed/NNG,금리/NNG,인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>연합인포맥스</td>\n",
       "      <td>[뉴욕채권-마감] 10년만기 국채수익률 작년보다 낮은 수준서 마쳐</td>\n",
       "      <td>2년만기 국채가격 4년래 최악의 한해 보내     10년만기 미국  국채수익률이  ...</td>\n",
       "      <td>만기/NNG,국채/NNG,가격/NNG,최악/NNG,보내/VV,만기/NNG,국채/NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>연합인포맥스</td>\n",
       "      <td>[뉴욕환시] `내년초 달러-엔에 주력'..달러 對엔 하락</td>\n",
       "      <td>2004년 마지막 거래일인 31일  뉴욕환시에서 미국 달러화는 개장초 102엔 근처...</td>\n",
       "      <td>마지막/NNG,거래일/NNG,뉴욕/NNG,환시/NNG,달러/NNG,개장/NNG,근처...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>연합인포맥스</td>\n",
       "      <td>[31일 뉴욕금융시장 요약] 한산한 거래속 새해 준비</td>\n",
       "      <td>) 한해 마지막 날인 31일 뉴욕 주요 금융시장은 한산한 거래속에 새해를 준비하는 ...</td>\n",
       "      <td>마지막/NNG,뉴욕/NNG,금융시장/NNG,한산/NNG,거래/NNG,새해/NNG,준...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-02</td>\n",
       "      <td>연합인포맥스</td>\n",
       "      <td>美 증시 기술주 주도로 2년 연속 상승..'01년래 최고</td>\n",
       "      <td>지난해 뉴욕증시는 기술주 주도로 2년  연속연초 대비 상승하면서 대표지수들을 지난 ...</td>\n",
       "      <td>주도/NNG,연속/NNG,대비/NNG,상승/NNG,대표지수/NNG,최고/NNG,오르...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   media                                 title  \\\n",
       "0  2005-01-01  연합인포맥스               내년 美국채수익률 5% 넘어서기 어려울 듯   \n",
       "1  2005-01-01  연합인포맥스  [뉴욕채권-마감] 10년만기 국채수익률 작년보다 낮은 수준서 마쳐   \n",
       "2  2005-01-01  연합인포맥스       [뉴욕환시] `내년초 달러-엔에 주력'..달러 對엔 하락   \n",
       "3  2005-01-01  연합인포맥스         [31일 뉴욕금융시장 요약] 한산한 거래속 새해 준비   \n",
       "4  2005-01-02  연합인포맥스       美 증시 기술주 주도로 2년 연속 상승..'01년래 최고   \n",
       "\n",
       "                                             content  \\\n",
       "0  2005년 10년만기 미국 국채수익률이  연방준비제도이사회(FRB)의 금리인상 지속...   \n",
       "1  2년만기 국채가격 4년래 최악의 한해 보내     10년만기 미국  국채수익률이  ...   \n",
       "2  2004년 마지막 거래일인 31일  뉴욕환시에서 미국 달러화는 개장초 102엔 근처...   \n",
       "3  ) 한해 마지막 날인 31일 뉴욕 주요 금융시장은 한산한 거래속에 새해를 준비하는 ...   \n",
       "4  지난해 뉴욕증시는 기술주 주도로 2년  연속연초 대비 상승하면서 대표지수들을 지난 ...   \n",
       "\n",
       "                                              ngrams  \n",
       "0  만기/NNG,국채/NNG,수익률/NNG,fed/NNG,fed/NNG,금리/NNG,인...  \n",
       "1  만기/NNG,국채/NNG,가격/NNG,최악/NNG,보내/VV,만기/NNG,국채/NN...  \n",
       "2  마지막/NNG,거래일/NNG,뉴욕/NNG,환시/NNG,달러/NNG,개장/NNG,근처...  \n",
       "3  마지막/NNG,뉴욕/NNG,금융시장/NNG,한산/NNG,거래/NNG,새해/NNG,준...  \n",
       "4  주도/NNG,연속/NNG,대비/NNG,상승/NNG,대표지수/NNG,최고/NNG,오르...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = df_news.dropna()\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news['tokens_ngram'] = df_news['ngrams'].apply(lambda x : ' '.join([w.split('/')[0] for w in x.split(',')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [tokens.split() for tokens in df_news['tokens_ngram'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['만기',\n",
       " '국채',\n",
       " '수익률',\n",
       " 'fed',\n",
       " 'fed',\n",
       " '금리',\n",
       " '인상',\n",
       " '지속',\n",
       " '따르',\n",
       " '인플레이션',\n",
       " '압력',\n",
       " '완화',\n",
       " '어렵',\n",
       " '전망',\n",
       " '인플레이션',\n",
       " '제어',\n",
       " '반면',\n",
       " '만기',\n",
       " '국채',\n",
       " '수익률',\n",
       " 'fed',\n",
       " '지속',\n",
       " '금리',\n",
       " '인상',\n",
       " '수준',\n",
       " '상승',\n",
       " '예측',\n",
       " '단기',\n",
       " '국채',\n",
       " '수익률',\n",
       " '상승',\n",
       " '나타나',\n",
       " '반면',\n",
       " '장기',\n",
       " '국채',\n",
       " '수익률',\n",
       " '상승',\n",
       " '제한',\n",
       " '일드커브',\n",
       " '플래트닝',\n",
       " '가속',\n",
       " '덧붙이',\n",
       " '고용창출',\n",
       " '호조',\n",
       " '수입',\n",
       " '증가',\n",
       " '견인',\n",
       " '고용시장',\n",
       " '호전',\n",
       " '소비자',\n",
       " '지출',\n",
       " '떠받치',\n",
       " '단기',\n",
       " '국채',\n",
       " '일드커브',\n",
       " '인플레이션',\n",
       " 'fed',\n",
       " '고용창출',\n",
       " '고용시장',\n",
       " '수입',\n",
       " '완화']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(\n",
    "    sentences = token_list,\n",
    "    size = 10,\n",
    "    alpha = 0.025,\n",
    "    min_count = 2,         # 2번 이하 무시\n",
    "    window=8,              # 이건 window_size : 앞 8 뒤 8 개\n",
    "    sample = 0.001,        # subsampling : tfidf처럼 , 낮은 점수는 샘플링을 하지 말자\n",
    "    sg = 1,                # skip-gram, 1 : skip-gram, 0 : CBOW\n",
    "    iter = 10              # 10번 돌리겠다\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram\n",
    "- 중심단어를 주고, 주변단어를 학습시키는 느낌?\n",
    "- 단어 하나에 4가지의 다른 경우가 많아(windowsize = 2 ) \n",
    "    - 일단 학습할게 많기 때문에, 성능은 좋다\n",
    "    - softmax -> 인풋 데이터가 많아서 오래 걸리는 단점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skip-gram에서의 연산량이 많아\n",
    "- 윈도우 안 : positive\n",
    "- 윈도우 밖 : negative\n",
    "\n",
    "속도를 줄이기 위해 Negative Sampling\n",
    "- 일부 단어 뽑아서, 윈도우 등장하지 않은 단어가 뽑힐 확률을 포함시켜서 한다..(빠름)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어의 vector 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3597359 ,  0.1704699 , -0.56658745, -0.09193325, -0.9747018 ,\n",
       "       -0.9856043 , -0.2714135 ,  0.5974886 ,  0.1895053 ,  0.0629601 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding = word2vec.wv.__getitem__('금리')\n",
    "word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어의 유사도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('내렸었', 0.9533522129058838), ('감하', 0.9496954083442688), ('내려감', 0.944301187992096), ('하한', 0.9394211769104004), ('최저대출금리', 0.9270777702331543), ('추이', 0.9260851144790649), ('중반', 0.9259750843048096), ('봤었', 0.9244350790977478), ('상되', 0.9232653379440308), ('반영', 0.9226080179214478)]\n"
     ]
    }
   ],
   "source": [
    "world_similar = word2vec.wv.most_similar('금리')\n",
    "print(world_similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast text\n",
    "\n",
    "- 이건 약간 형태소별로 쪼개서 새로운 데이터라던가 더 걸려."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "fasttext = FastText(token_list,\n",
    "                   size=10,\n",
    "                   window=8,\n",
    "                   min_count=2,\n",
    "                   alpha=0.025,\n",
    "                   sg=1,\n",
    "                   iter=10,\n",
    "                   min_n = 3,\n",
    "                   max_n = 6\n",
    "                   )\n",
    "\n",
    "# 이것도 할 수 있다고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "sentences = [['I', 'bow', 'my', 'head'], ['I', 'shoot', 'a', 'bow']] # 뜻이 다른 경우 어떻게 될까요\n",
    "\n",
    "model = Word2Vec(sentences,\n",
    "                s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
