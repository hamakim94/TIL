## 단어의 표현

1. One-Hot Encoding

   단어를 숫자로 표현하고자 할 때 적용할 수 있는 '간단한' 방법론

   한계점 

   - 단어의 수 만큼 차원이 필요함

   - 단어간 의미를 추출하지 못함(코사인 유사도가 0이 나온다)



2. 단어 임베딩

   단어 임베딩은 단어의 의미를 간직하는 밀집 벡터(Dense Vector)로 표현하는 방법

   벡터가 공간에 꽉 차 있어서 연산을 줄일 수 있는 이점이 있음(2차원)

   그러면 어떻게 만들어?

   - '같은 문맥에서 등장하는 단어는 유사한 의미를 지닌다' : 분포 가설

     임의의 위치에 벡터를 생성하고, 같은 문맥에 등장하는 단어를 가까이 표현

     그래서 단어들 사이의 거리를 측정해야 하는데

     	1. 유클리드 거리
      	2. 코사인 유사도
      	3. 레벤슈타인 유사도 등이 있다

3.  n-Gram

   복수개(n개) 단어를 보느냐에 따라 unigram, bigram, trigram 등으로 구분한다.

   제한적으로 문맥을 표현할 수 있음

   그래서 보통 연어를 처리할 때 많이 쓰인다.!



## 문서의 표현

여기서 문서는 보통 문장을 표현하더라..

### Bag of Words

- 문서 내 단어 출현 순서는 무시하고, '빈도수'를 기반으로 문서를 표현하는 방법!!!

단점

- 단어의 순서를 고려하지 않는다
- Spare함, 벡터 공간의 낭비
- 단어의 빈도수가 중요도를 바로 의미하진 않는다.
- 전처리가 매우 중요함, 같은 의미의 다른 언어 표현이 있을 경우 다른 것으로 인식



### TDM ( Term Document Matrix), DTM

- BoW 중 하나
- 문서에 등장하는 각 단어 빈도를 행렬로 표현한 것

- TDM 행이 용어, 열이 Document, DTM은 행이 문서, 열이 Term

단점

- BoW랑 Same

그래서 나온 개념이?

### TF-IDF

- 단어 빈도 - 역문서 빈도
- TDM 내 각 단어의 중요성을 가중치로 표현
- TDM을 사용하는 것 보다 더 정확하게 문서 비교가 가능하다
- 특정 문서 d에서 특정 단어 t의 등정 횟수 * 특정 단어 t가 등장한 문서의 수의 역수
- tf가 높고, t가 높으면 결국 그 특정 문서만 나온 키워드를 찾을 수 있음!



- 결국 단어와 문서사이의 연관성을 체크 가능하고
- 정보 검색 : 검색어와 가장 관련이 있는 문서를 찾아 결과를 제공하기도 한다
  	- 검색엔진에서의 '인공지능'
- 키워드 추출 : TF-IDF 점수가 가장 높은 점수를 가지고 있는 단어가 그 문서를 대표하는 키워드



계산 절차

- 토큰 Index 사용

- TF 계싼 / IDF 계산 / TF-IDF 계산

  