{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9-2 Textrank\n",
    "\n",
    "문장간 유사성이 있는 경우는 connection이 있다고 생각한다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![대체 텍스트](https://www.researchgate.net/profile/Khushboo_Thakkar3/publication/232645575/figure/fig1/AS:575720050573312@1514273764062/Sample-graph-build-for-sentence-extraction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 TextRank 직접 구현하기 (Matrix 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"딸기 바나나 사과 파인애플. 바나나 사과 딸기 포도. 복숭아 수박. 파인애플 사과 딸기 바나나.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab(dicpath = 'C:\\mecab\\mecab-ko-dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = Text.split('. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['딸기 바나나 사과 파인애플', '바나나 사과 딸기 포도', '복숭아 수박', '파인애플 사과 딸기 바나나.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('파인애플', 'NNG'), ('사과', 'NNG'), ('딸기', 'NNG'), ('바나나', 'NNG'), ('.', 'SF')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일단 명사인 것만 빼와서 token list 만들지\n",
    "sentence_token = []\n",
    "for i in \n",
    "mecab.pos(sentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 문장간 유사도 측정 (자카드 유사도 사용)\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    set1 = set(mecab.pos(sentence1))\n",
    "    set2 = set(mecab.pos(sentence2))\n",
    "    \n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "    \n",
    "\n",
    "sentence_similarity('나는 치킨을 좋아해','나는 치킨을 싫어해')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "    def buildMatrix(sentences):\n",
    "        score = None\n",
    "    # 문장별로 그래프 edge를 Matrix 형태로 생성\n",
    "        weighted_edge = None\n",
    "    \n",
    "        return score, weighted_edge\n",
    "\n",
    "Text = \"딸기 바나나 사과 파인애플 수박. 바나나 사과 딸기 포도. 복숭아 수박. 파인애플 사과 딸기 바나나.\"\n",
    "buildMatrix(sent_tokenize(Text))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildMatrix(sentences):\n",
    "    \n",
    "    len_sent = len(sentences)\n",
    "\n",
    "    f_weighted_edge = np.zeros((len_sent, len_sent), np.float32)\n",
    "    weighted_edge = np.zeros((len_sent, len_sent), np.float32)\n",
    "    # we must get first score in order to make score\n",
    "    for i in range(len_sent):\n",
    "        for j in range(len_sent):\n",
    "            if not i == j:\n",
    "                f_weighted_edge[i][j] = sentence_similarity(sentences[i], sentences[j])\n",
    "\n",
    "    score = f_weighted_edge.sum(axis=1)     \n",
    "    # print(score)\n",
    "    # print(weighted_edge)\n",
    "\n",
    "    for i in range(len_sent):\n",
    "        for j in range(len_sent):\n",
    "            if not i == j:\n",
    "                if score[i] == 0:\n",
    "                    weighted_edge[i][j] = 0\n",
    "                else:\n",
    "                    weighted_edge[i][j] = sentence_similarity(sentences[i], sentences[j])/score[i]\n",
    "\n",
    "    return score, weighted_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4000001 1.1       0.        1.3      ]\n",
      "[[0.         0.4285714  0.         0.57142854]\n",
      " [0.54545456 0.         0.         0.45454544]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.61538464 0.3846154  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "score, weighted_edge = buildMatrix(sentences)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97142856"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.1 * 0.4285714 + 1.3*0.3846154"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 문장 중요도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score, weighted_edge, eps=0.0001, d=0.85, max_iter = 50):\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        prev_score = np.copy(score)\n",
    "        score = np.dot(weighted_edge.T, score)\n",
    "        \n",
    "        if np.sum(np.fabs(score - prev_score)) <= eps:\n",
    "            break\n",
    "                \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4, 1.1, 0. , 1.3], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gotit = scoring(score, weighted_edge)\n",
    "gotit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4, 1.1, 0. , 1.3], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 문서 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def summarize(text, n=10):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize(Text, 3)\n",
    "\n",
    "for sent in summary :\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 TextRank 직접 구현하기 (Graph 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"딸기 바나나 사과 딸기 파인애플. 바나나 사과 딸기. 복숭아 파인애플. 파인애플 사과 딸기 바나나.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences(text):\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 자카드 유사도\n",
    "\n",
    "- 겹치는 토큰의 비율!!  \n",
    "\n",
    "근데 그러면 score 필요하잖아.. 그러면 어떻게?\n",
    "\n",
    "- 문장 1 -> 문장 2   \n",
    "\n",
    "\n",
    "( 문장 1 - 문장2 유사도) / (문장1 전체 유사도 합(0.5 / (0.5 + 0.8 + 0.167) -> 이거 자체가 score!\n",
    "\n",
    "유사도를 기반으로, 그냥 초기 스코어를 edge 유사도의 합으로 구해(들어온거)  \n",
    "\n",
    "그 다음 egge 가중치\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "# 문장간 유사도 측정 (자카드 유사도 사용)\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "  pass\n",
    "\n",
    "sentence_similarity('나는 치킨을 좋아해','나는 치킨을 싫어해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(nodes):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def rank(nodes,edges):\n",
    "    passi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 문서 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text,num_summaries=3):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=summarize(Text, 3)\n",
    "\n",
    "for sent in summary :\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 gensim을 활용한 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "summarize(docs[1]).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
