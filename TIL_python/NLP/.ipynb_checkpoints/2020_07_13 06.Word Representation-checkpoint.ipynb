{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë‹¨ì–´ì˜ í‘œí˜„(Word Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê¸°ê²ŒëŠ” ë¬¸ìë¥¼ ê·¸ëŒ€ë¡œ ì¸ì‹í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ìˆ«ìë¡œ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. One-Hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1, ì§ì ‘ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"ì›ìˆ­ì´, ë°”ë‚˜ë‚˜, ì‚¬ê³¼\" ë¡œ ì›-í•« ì¸ì½”ë”©ì„ í•œë‹¤ë©´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì¸ì½”ë”© ëŒ€ìƒ ë‹¨ì–´ë“¤ì„ ë‹´ì€ ë¦¬ìŠ¤íŠ¸ \n",
    "word_ls = ['ì›ìˆ­ì´','ë°”ë‚˜ë‚˜','ì‚¬ê³¼','ì‚¬ê³¼'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(word_ls):\n",
    "    # ê³ ìœ  ë‹¨ì–´ì™€ ì¸ë±ìŠ¤ë¥¼ ë§¤ì¹­ì‹œì¼œì£¼ëŠ” ì‚¬ì „ ìƒì„± \n",
    "    word2id_dic = defaultdict(lambda:len(word2id_dic))\n",
    "    \n",
    "    # {ë‹¨ì–´ : ì¸ë±ìŠ¤} ì‚¬ì „ êµ¬ì¶• for\n",
    "    for word in word_ls:\n",
    "        word2id_dic[word] \n",
    "        \n",
    "    n_unique_words = len(word2id_dic) # ê³ ìœ ë‹¨ì–´ê°œìˆ˜\n",
    "    one_hot_vectors = np.zeros((len(word_ls), n_unique_words))\n",
    "    \n",
    "    for i, word in enumerate(word_ls):\n",
    "        index = word2id_dic[word]# í•´ë‹¹ ë‹¨ì–´ì˜ ê³ ìœ  ì¸ë±ìŠ¤ \n",
    "        one_hot_vectors[i, index] = 1\n",
    "    \n",
    "    return one_hot_vectors\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_vectors= one_hot_encode(word_ls) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"ì½”ë¼ë¦¬\"ë¼ëŠ” ë‹¨ì–´ê°€ ì¶”ê°€ëœë‹¤ë©´?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ls = ['ì›ìˆ­ì´','ë°”ë‚˜ë‚˜','ì‚¬ê³¼','ì½”ë¼ë¦¬']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vectors = one_hot_encode(word_ls)\n",
    "one_hot_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 sklearn í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearnì„ í™œìš©í•œ one-hot encoding\n",
    "from numpy import array\n",
    "from numpy import argmax # í™•ë¥ ë¡œ, ê°€ì¥ í° ë†ˆì„ ë½‘ì•„ë‚´ëŠ”ê²ƒ\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì›ìˆ­ì´' 'ë°”ë‚˜ë‚˜' 'ì‚¬ê³¼' 'ì½”ë¼ë¦¬']\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì œ ë°ì´í„° ë°°ì—´\n",
    "values = array(word_ls)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 3]\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ìì—´ì— ìˆ«ìë¥¼ ë¶™ì„\n",
    "label_enc = LabelEncoder()\n",
    "int_enc = label_enc.fit_transform(values)\n",
    "print(int_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [0]\n",
      " [1]\n",
      " [3]]\n",
      "[[0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# binary encode\n",
    "onehot_enc = OneHotEncoder(sparse=False) # Sparse Trueë¡œ í•˜ë©´ indexê¹Œì§€ í‘œí˜„\n",
    "# onehot_enc = OneHotEncoder(sparse=True)\n",
    "int_enc = int_enc.reshape(len(int_enc), 1) # n:1 matrixë¡œ ë³€í™˜\n",
    "print(int_enc)\n",
    "onehot_enc = onehot_enc.fit_transform(int_enc)\n",
    "print(onehot_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì›ìˆ­ì´']\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding ì˜ ì²«ë²ˆì§¸ ë°°ì—´ì„ ê°’ì„ ì—­ìœ¼ë¡œ ì‚°ì¶œ\n",
    "inverted = label_enc.inverse_transform([argmax(onehot_enc[0, :])]) # ì²«ë²ˆì§¸ í–‰\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_enc[0, :] # 0ë²ˆì§¸ í–‰ì˜ ëª¨ë“ ê±¸ ê°€ì§€ê³ ì™€~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax(onehot_enc[0, :]) # ê°€ì¥ í° indexë¥¼ ê°€ì ¸ì™€ì¤˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 ë°€ì§‘ ë²¡í„° (Dense Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dic = {\n",
    "'ì‚¬ê³¼' : [1.0, 0.5],\n",
    "'ë°”ë‚˜ë‚˜' : [0.9, 1.2],\n",
    "'ì›ìˆ­ì´' : [0.5, 1.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 ìœ ì‚¬ë„ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 ìœ í´ë¦¬ë””ì–¸ ê±°ë¦¬(Euclidean distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‘ ë²¡í„°ì‚¬ì´ì˜ ì§ì„  ê±°ë¦¬. í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ë¥¼ ìƒê°í•˜ë©´ ì´í•´í•˜ê¸° ì‰¬ì›€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def euclidean_dist(x,y): # npê¸°ë°˜ì´ê¸°ë•Œë¬¸ì— ë°ì´í„°ë¥¼ ë‹¤ì‹œ arrayë¡œ\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return np.sqrt(np.sum(x-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‚¬ê³¼ì™€ ë°”ë‚˜ë‚˜ì˜ ìœ í´ë¦¬ë””ì•ˆ ìœ ì‚¬ë„\n",
    "euclidean_dist(word_embedding_dic['ì‚¬ê³¼'], word_embedding_dic['ë°”ë‚˜ë‚˜'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 ì½”ì‚¬ì¸ ìœ ì‚¬ë„(Cosine Similarity)\n",
    "- ë‘ ë²¡í„°ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜\n",
    "- ë‘ ë²¡í„° ì‚¬ì´ì˜ ì½”ì‚¬ì¸ì„ ì¸¡ì •\n",
    "- 0ë„ = 1, 90ë„ = 0, 180ë„ = -1 ==> 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬ë„ê°€ ë†’ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "# xì™€ y, ë‘ ë²¡í„°ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "    nominator = np.dot(x, y) # ë¶„ì\n",
    "    denominator = np.linalg.norm(x)*np.linalg.norm(y) # ë¶„ëª¨\n",
    "    return nominator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =np.array([1, 2])\n",
    "b = np.array([3, 4])\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpyì˜ linalg ì„œë¸Œ íŒ¨í‚¤ì§€ì˜ norm ëª…ë ¹ìœ¼ë¡œ ë²¡í„°ì˜ ê¸¸ì´ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤. ìœ„ì—ì„œ ì˜ˆë¡œ ë“  2ì°¨ì› ë²¡í„° ğ‘=[1,2] ì˜ ê¸¸\n",
    "ì´ëŠ” âˆš5â‰ˆ2.236 ì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8944271909999159\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ê³¼ì™€ ë°”ë‚˜ë‚˜ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "print(cosine_similarity(word_embedding_dic['ì‚¬ê³¼'], word_embedding_dic['ë°”ë‚˜ë‚˜']))\n",
    "print(euclidean_dist(word_embedding_dic['ì‚¬ê³¼'], word_embedding_dic['ë°”ë‚˜ë‚˜']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067811865475\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ê³¼ì™€ ì›ìˆ­ì´ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "print(cosine_similarity(word_embedding_dic['ì‚¬ê³¼'], word_embedding_dic['ì›ìˆ­ì´']))\n",
    "print(euclidean_dist(word_embedding_dic['ì‚¬ê³¼'], word_embedding_dic['ì›ìˆ­ì´']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9486832980505138\n",
      "0.09999999999999998\n"
     ]
    }
   ],
   "source": [
    "# ë°”ë‚˜ë‚˜ì™€ ì›ìˆ­ì´ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "print(cosine_similarity(word_embedding_dic['ë°”ë‚˜ë‚˜'], word_embedding_dic['ì›ìˆ­ì´']))\n",
    "print(euclidean_dist(word_embedding_dic['ë°”ë‚˜ë‚˜'], word_embedding_dic['ì›ìˆ­ì´']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 ìì¹´ë“œ ìœ ì‚¬ë„(Jaccard index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'ëŒ€ë¶€ë¶„ ì›ìˆ­ì´ëŠ” ë°”ë‚˜ë‚˜ë¥¼ ì¢‹ì•„í•©ë‹ˆë‹¤.'\n",
    "s2 = 'ì½”ì£¼ë¶€ ì›ìˆ­ì´ëŠ” ë°”ë‚˜ë‚˜ë¥¼ ì‹«ì–´í•©ë‹ˆë‹¤.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ì¢‹ì•„í•©ë‹ˆë‹¤.', 'ëŒ€ë¶€ë¶„', 'ì½”ì£¼ë¶€', 'ë°”ë‚˜ë‚˜ë¥¼', 'ì‹«ì–´í•©ë‹ˆë‹¤.', 'ì›ìˆ­ì´ëŠ”'}\n",
      "{'ì›ìˆ­ì´ëŠ”', 'ë°”ë‚˜ë‚˜ë¥¼'}\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# í† í°í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "token_s1 = s1.split()\n",
    "token_s2 = s2.split()\n",
    "\n",
    "union = set(token_s1).union(set(token_s2))\n",
    "print(union)\n",
    "\n",
    "intersection = set(token_s1).intersection(set(token_s2))\n",
    "print(intersection)\n",
    "      \n",
    "print(len(intersection)/len(union)) # 2ë¥¼ 6ë¡œ ë‚˜ëˆ”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "\n",
    "from collections import defaultdict\n",
    "d_dict = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dict['a'] \n",
    "d_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2iddict = defaultdict(lambda : len(word2iddict))\n",
    "# í˜¸ì¶œë ë•Œë§ˆë‹¤ lambda ì“°ê² ë‹¤ ì´ë§ì´ì•¼!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2iddict['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2iddict['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>, {'a': 0, 'b': 1})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2iddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
